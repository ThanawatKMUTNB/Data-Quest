{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  \n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        params = {'text':text}\n",
    "        response = requests.get(self._url, headers=self._headers, params=params)\n",
    "        try:\n",
    "            polarity = str(response.json()['sentiment']['polarity'])\n",
    "        except (KeyError):\n",
    "            polarity = 'neutral'\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d') #dmY ทีหลัง\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        return self.df\n",
    "    \n",
    "    def setnewDF(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "\n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return\n",
    "        return dff.loc[mask]\n",
    "\n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectword(self,dataframe):            #before edit collect thai can not use\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        word = {}\n",
    "        for i in dataframe['Tweet']:    #only tweet\n",
    "            if langdetect.detect(i) != 'th':\n",
    "                allwords = i.split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                allwords = word_tokenize(i, engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "        del word['RT']\n",
    "        del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        return sortword     #tuple in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>shounen ai</td>\n",
       "      <td>myrialune</td>\n",
       "      <td>zoebug71 Also my favouriteeeee shounen ai ever...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>shounen ai</td>\n",
       "      <td>MintFrogkie</td>\n",
       "      <td>abcdefghijklmvh cloudyyamilee SRY FOR LATE RES...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4061</th>\n",
       "      <td>shounen ai</td>\n",
       "      <td>AthyChii</td>\n",
       "      <td>Boy Meets Maria Completed Shounen Ai</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>shounen ai</td>\n",
       "      <td>mkn0135</td>\n",
       "      <td>RT AthyChii Boy Meets Maria Completed Shounen Ai</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>shounen ai</td>\n",
       "      <td>ruinedlunarian</td>\n",
       "      <td>The only Gundam poster I own and it looks like...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>ncwmqj</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>__RaInBoWLiGhT</td>\n",
       "      <td>RT btfeffectx ผมอยากแนะนำ EIGHTYSIX ให้ทุกคนดู...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>lilinjeee</td>\n",
       "      <td>Teddix หนูขอแนะนำ Great pretender ค่ะ เป็นอนิเ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>ncwmqj</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>littleslothseiy</td>\n",
       "      <td>RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1006</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4553 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keyword             User  \\\n",
       "4050   shounen ai        myrialune   \n",
       "4051   shounen ai      MintFrogkie   \n",
       "4061   shounen ai         AthyChii   \n",
       "4062   shounen ai          mkn0135   \n",
       "4063   shounen ai   ruinedlunarian   \n",
       "...           ...              ...   \n",
       "4738  อนิเมะแนะนำ           ncwmqj   \n",
       "4876  อนิเมะแนะนำ   __RaInBoWLiGhT   \n",
       "4877  อนิเมะแนะนำ        lilinjeee   \n",
       "4878  อนิเมะแนะนำ           ncwmqj   \n",
       "4902  อนิเมะแนะนำ  littleslothseiy   \n",
       "\n",
       "                                                  Tweet Language       Time  \\\n",
       "4050  zoebug71 Also my favouriteeeee shounen ai ever...       en 2022-03-25   \n",
       "4051  abcdefghijklmvh cloudyyamilee SRY FOR LATE RES...       en 2022-03-25   \n",
       "4061               Boy Meets Maria Completed Shounen Ai       en 2022-03-25   \n",
       "4062   RT AthyChii Boy Meets Maria Completed Shounen Ai       en 2022-03-25   \n",
       "4063  The only Gundam poster I own and it looks like...       en 2022-03-25   \n",
       "...                                                 ...      ...        ...   \n",
       "4738  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...       th 2022-03-26   \n",
       "4876  RT btfeffectx ผมอยากแนะนำ EIGHTYSIX ให้ทุกคนดู...       th 2022-03-26   \n",
       "4877  Teddix หนูขอแนะนำ Great pretender ค่ะ เป็นอนิเ...       th 2022-03-26   \n",
       "4878  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...       th 2022-03-26   \n",
       "4902  RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...       th 2022-03-26   \n",
       "\n",
       "        User Location     Hashtag  Polarity  Likes  Retweet  Sentiment  \n",
       "4050              NaN          []   neutral      2        0       0.00  \n",
       "4051              NaN          []  negative      1        0      -0.30  \n",
       "4061              NaN          []   neutral     12        1       0.00  \n",
       "4062              NaN          []   neutral      0        1       0.00  \n",
       "4063              NaN          []  positive      0        0       0.30  \n",
       "...               ...         ...       ...    ...      ...        ...  \n",
       "4738              NaN  ['แนะนำอ']  positive      0       33      66.67  \n",
       "4876              NaN          []  negative      0        9      66.67  \n",
       "4877              NaN          []  negative      0        0      75.00  \n",
       "4878              NaN  ['แนะนำอ']  positive      0       33      66.67  \n",
       "4902  𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻          []  positive      0     1006      66.67  \n",
       "\n",
       "[4553 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "#dm.unionfile(filename)\n",
    "dm.unionfile(['tweet_data_2732022.csv'])\n",
    "dm.getperiod('2022-03-25',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('นิยาย', 424)\n",
      "('Pixar', 245)\n",
      "('แฟนตาซี', 231)\n",
      "('ตอน', 198)\n",
      "('ใหม่', 191)\n",
      "('ต่าง', 184)\n",
      "('shounen', 179)\n",
      "('โลก', 177)\n",
      "('เด็กดี', 132)\n",
      "('Algiz', 118)\n"
     ]
    }
   ],
   "source": [
    "df1 = dm.getrowwithkeys(['ต่างโลก','pixar','shounen']).sort_values('Keyword')\n",
    "for word in dm.collectword(df1)[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dm.collectword(df1)[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022_1.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['pixar','อนิเมะ'])]\n",
    "word = {}\n",
    "\n",
    "for i in dff['Tweet']:\n",
    "    if langdetect.detect(i) != 'th':\n",
    "        allwords = i.split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        allwords = word_tokenize(i, engine='newmm')\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect complete\n"
     ]
    }
   ],
   "source": [
    "#tweet_data.csv to keyword files\n",
    "import glob\n",
    "import pandas as pd\n",
    "start = 0\n",
    "filenames = glob.glob(str(str(os.getcwd())+\"\\\\Data\\\\*.csv\"))\n",
    "for file in filenames:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if start != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        start += 1\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "\n",
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "folder = \"collectkeys\"\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)    \n",
    "for key in keys:\n",
    "    path = str(folder+'/'+key)\n",
    "    dff = df.loc[df['Keyword'].isin([key])]\n",
    "    days = list(set(dff['Time'].tolist()))\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for d in days:\n",
    "        dfff = dff.loc[dff['Time'].isin([d])]\n",
    "        dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "print('collect complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"kE7s0TJ00spb9kEPZ1BC7w8A16dpy8Cr\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "        self.keys = os.listdir(\"collectkeys\")\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        # print(text)\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        # print(text)\n",
    "        params = {'text':text}\n",
    "        # print(json.dumps(params, sort_keys=False, indent=4))\n",
    "        try:\n",
    "            response = requests.get(self._url, headers=self._headers, params=params)\n",
    "            try:\n",
    "                polarity = str(response.json()['sentiment']['polarity'])\n",
    "            except (KeyError):\n",
    "                polarity = 'neutral'\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            polarity = 'URI too long'\n",
    "            pass\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d')\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        self.keys = list(set(self.df['Keyword'].tolist()))\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def newUnion(self):\n",
    "        path=os.getcwd()\n",
    "        keys = []\n",
    "        start = 0\n",
    "        for f in glob.glob(path+'/collectkeys/*'):\n",
    "            keyname = os.path.split(f)[-1]\n",
    "            keys.append(keyname)\n",
    "        for k in keys:\n",
    "            for file in glob.glob(path+'/collectkeys/'+k+'/*.csv'):\n",
    "                if start == 0:\n",
    "                    self.df = pd.read_csv(file)\n",
    "                    start +=1\n",
    "                else:\n",
    "                    dff = pd.read_csv(file)\n",
    "                    self.df = pd.concat([self.df,dff])\n",
    "        self.keys = keys\n",
    "        #self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def setnewdf(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def concatfile(self,dataframe):\n",
    "        self.df = pd.concat([self.df,dataframe])\n",
    "        self.df.drop_duplicates(keep='last',inplace=True)\n",
    "        self.df.sort_values(by=['Keyword'],inplace=True)\n",
    "        self.formatdatetime('Time')\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        #self.df = self.unionfile(self.filenames)\n",
    "        self.df = self.newUnion()\n",
    "        return self.df\n",
    "    \n",
    "    def collectfile(self):\n",
    "        self.df[\"Time\"] = pd.to_datetime(self.df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "        keys = list(set(self.df['Keyword'].tolist()))\n",
    "        folder = \"collectkeys\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)    \n",
    "        for key in keys:\n",
    "            path = str(folder+'/'+key)\n",
    "            dff = self.df.loc[self.df['Keyword'].isin([key])]\n",
    "            days = list(set(dff['Time'].tolist()))\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            for d in days:\n",
    "                dfff = dff.loc[dff['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "        print('collect complete')\n",
    "\n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return dff\n",
    "        return dff.loc[mask]\n",
    "\n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectwords(self,dataframe):\n",
    "        #print(dataframe)\n",
    "        nltk.download('stopwords')          #important\n",
    "        dataframe = dataframe.reset_index()\n",
    "        th_stopwords = list(thai_stopwords())\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        en_stops.update(list(string.ascii_lowercase))\n",
    "        en_stops.update(list(string.ascii_uppercase))\n",
    "        word = {}\n",
    "        for index,row in dataframe.iterrows():    #only tweet\n",
    "            if row['Language'] == 'en':\n",
    "                allwords = str(row['Tweet']).split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            elif row['Language'] == 'th':\n",
    "                allwords = word_tokenize(row['Tweet'], engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in th_stopwords:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                pass\n",
    "        if 'RT' in word:\n",
    "            del word['RT']  #for twitter\n",
    "        if ' ' in word:\n",
    "            del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        worddf = pd.DataFrame(sortword,columns=['Word','Count'])\n",
    "        return worddf   #word dataframe\n",
    "        #return sortword     #tuple in list\n",
    "    \n",
    "    def deletekeyword(self,keyword):\n",
    "        path=os.getcwd()\n",
    "        for k  in keyword:\n",
    "            shutil.rmtree(path+'//collectkeys//'+k+'//')\n",
    "            self.keys.remove(k)\n",
    "            #self.df.drop(self.df[self.df['Keyword']==k].index,inplace = True)\n",
    "            self.df = self.newUnion()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_Scrap:\n",
    "    def __init__(self):\n",
    "\n",
    "        #twitter api\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        #thai api\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"}\n",
    "\n",
    "        self.df = None\n",
    "        self.keys = []\n",
    "\n",
    "    def setdataframe(self,df):\n",
    "        self.df = df\n",
    "        self.keys = self.df['Keyword'].tolist()\n",
    "        self.keys = list(set(self.keys))\n",
    "\n",
    "    def getheader(self):\n",
    "        return self.df.columns.tolist()\n",
    "    \n",
    "    def getSentiment(self,text):\n",
    "\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "    \n",
    "    def extract_hashtags(self,text):\n",
    "\n",
    "        regex = \"#(\\w+)\" \n",
    "        hashtag_list = re.findall(regex, text)\n",
    "        return hashtag_list\n",
    "\n",
    "    def remove_url(self,txt):\n",
    "\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "    \n",
    "    def remove_url_th(self,txt):\n",
    "        return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())\n",
    "\n",
    "    def get_related_tweets(self,key_word,until):\n",
    "\n",
    "        tweet_keyword = []\n",
    "        twitter_users = []\n",
    "        twitter_users_location = []\n",
    "        tweet_hashtag = []\n",
    "        tweet_time = []\n",
    "        tweet_string = [] \n",
    "        tweet_countRT = []\n",
    "        tweet_fav = []\n",
    "        tweet_sentiment = []\n",
    "        tweet_polarity = []\n",
    "        tweet_language = []\n",
    "        for tweet in tw.Cursor(self._api.search_tweets,\n",
    "                                q=key_word,\n",
    "                                tweet_mode=\"extended\",\n",
    "                                until=until,\n",
    "                                include_entities=True).items(20):\n",
    "                                \n",
    "            if(tweet.lang == 'en'or tweet.lang == 'th'):\n",
    "                twitter_users.append(tweet.user.screen_name)\n",
    "                twitter_users_location.append(tweet.user.location)\n",
    "                tweet_time.append(tweet.created_at)\n",
    "                tweet_countRT.append(tweet.retweet_count)\n",
    "                tweet_fav.append(tweet.favorite_count)\n",
    "                tweet_keyword.append(key_word)\n",
    "                tweet_hashtag.append(str(self.extract_hashtags(tweet.full_text)))\n",
    "                tweet_language.append(tweet.lang)\n",
    "                if tweet.lang == 'en':\n",
    "                    tweet_string.append(self.remove_url(tweet.full_text))\n",
    "                    tweet_polarity.append(self.getSentiment(tweet.full_text))\n",
    "                    tweet_sentiment.append(TextBlob(tweet.full_text).sentiment.polarity)\n",
    "                elif tweet.lang == 'th':\n",
    "                    tweet_string.append(self.remove_url_th(tweet.full_text))\n",
    "                    text = re.sub(r'[%]',' ',tweet.full_text)\n",
    "                    params = {'text':text}\n",
    "                    response = requests.get(self._url, headers=self._headers, params=params)\n",
    "                    try:\n",
    "                        polarity = str(response.json()['sentiment']['polarity'])\n",
    "                        sentiment = str(response.json()['sentiment']['score'])\n",
    "                    except (KeyError):\n",
    "                        polarity = 'neutral'\n",
    "                        sentiment = 0\n",
    "                    tweet_polarity.append(polarity)\n",
    "                    tweet_sentiment.append(sentiment)\n",
    "\n",
    "        self.df = pd.DataFrame({'Keyword':tweet_keyword,'User':twitter_users,'Tweet': tweet_string,'Language':tweet_language, 'Time': tweet_time,'User Location':twitter_users_location,\n",
    "                            'Hashtag':tweet_hashtag,'Polarity':tweet_polarity,'Likes':tweet_fav,'Retweet':tweet_countRT,'Sentiment':tweet_sentiment})\n",
    "\n",
    "        \n",
    "        self.df['Time'] = pd.to_datetime(self.df['Time']).dt.strftime('%Y-%m-%d')\n",
    "        #self.df['Time'] = pd.to_datetime(self.df['Time'])\n",
    "        folder = \"collectkeys\"\n",
    "        path = str(folder+'/'+key_word)\n",
    "        days = list(set(self.df['Time'].tolist()))\n",
    "        if key_word not in self.keys:\n",
    "            \n",
    "            if not os.path.exists(path):    \n",
    "                os.mkdir(path)              #create direc for keyword\n",
    "            for d in days:\n",
    "                dfff = self.df.loc[self.df['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key_word+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "            print('save new file comp')\n",
    "        else:\n",
    "            print('save old key')\n",
    "            for d in days:\n",
    "                dfff = self.df.loc[self.df['Time'].isin([d])]\n",
    "                csvname = str(path+'/'+key_word+'_'+d+'.csv')\n",
    "                if csvname in glob.glob(str(str(os.getcwd())+\"\\\\collectkeys\\\\*.csv\")):\n",
    "                    olddf = pd.read_csv(csvname)\n",
    "                    newdf = pd.concat([dfff,olddf])\n",
    "                    newdf.drop_duplicates(keep='last',inplace=True)\n",
    "                    os.remove(csvname)\n",
    "                    newdf.to_csv(filename,encoding='utf-8',index=False)\n",
    "                else:\n",
    "                    dfff.to_csv(csvname,encoding='utf-8',index=False)\n",
    "            print('save file comp')\n",
    "        return self.df\n",
    "\n",
    "    def savedata(self,keyword,until): #keyword is list\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print('\\nstart saving @',current_time)\n",
    "        #today = datetime.today()\n",
    "        #filename = str(\"tweet_data_\"+str(today.day)+str(today.month)+str(today.year)+\".csv\")\n",
    "\n",
    "        # if filename not in glob.glob(\"*.csv\"):\n",
    "        #     self.df = pd.DataFrame(columns=['Keyword','User','Tweet','Language','Time','User Location','Hashtag','Polarity','Likes','Retweet','Sentiment'])\n",
    "        # else:\n",
    "        #     self.df = pd.read_csv(filename)\n",
    "\n",
    "        for kw in keyword:\n",
    "            self.df = pd.concat([self.df,self.get_related_tweets(kw,until)])\n",
    "\n",
    "        self.df.drop_duplicates(keep='last',inplace=True)\n",
    "        self.df.sort_values(by=['Keyword'],inplace=True)\n",
    "        # if filename in glob.glob(\"*.csv\"):\n",
    "        #     os.remove(filename)\n",
    "        # self.df.to_csv(filename,encoding='utf-8',index=False)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print('save complete @',current_time)\n",
    "\n",
    "    def searchkeys(self,keyword,Ans,until):   #keyword's type is list\n",
    "        #print('keyword',keyword,'\\nkeys',self.keys,'\\nkeyword in keys?',keyword in self.keys)\n",
    "        # if \"\" in keyword:\n",
    "        #     return self.df\n",
    "        \n",
    "        if len(keyword) > 1:            #>1 keyword\n",
    "            dhave = []\n",
    "            for key in keyword:\n",
    "                if key not in self.keys:\n",
    "                    dhave.append(key)\n",
    "            print(keyword)\n",
    "            print(dhave)\n",
    "            if len(dhave) > 0:          #search new keyword\n",
    "                \n",
    "                self.savedata(dhave,until)\n",
    "                self.keys.extend(dhave)\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            elif Ans == \"real\":         #search old keys real time\n",
    "                self.savedata(keyword,until)\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            else:\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "        elif keyword[0] in self.keys:   #1 key in old keys\n",
    "            if Ans == \"real\":\n",
    "                self.savedata(keyword,until)\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            else:\n",
    "                return self.df.loc[self.df['Keyword']==keyword[0]]\n",
    "        else:              #1keyword (new)\n",
    "            if Ans == 'yes':            #new key 1 key\n",
    "                \n",
    "                self.savedata(keyword,until)\n",
    "                self.keys.extend(keyword)\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            # elif Ans == \"real\":\n",
    "            #     self.savedata(keyword,until)\n",
    "            #     return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            else:\n",
    "                print('You select NO')\n",
    "                return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>AnimatorsPal</td>\n",
       "      <td>RT AnimationVFXJob Marvel Streaming Production...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>['freelanceremotecontractworkfromhome', 'produ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>SirFowlman</td>\n",
       "      <td>RT OleLoken I drew a lady on a vespa then i dr...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Australia</td>\n",
       "      <td>['2d', '2danimation']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>cadetcollar</td>\n",
       "      <td>this 100 true lol as an animation student i wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>she/her | 22</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>_Fungai_</td>\n",
       "      <td>RT animationjobs 2D Production Supervisor job ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>peridopp</td>\n",
       "      <td>RT KoalaDingoLabo The koala facing the frogsga...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>['gamedev', 'madewithunity', 'unity3d', 'metro...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Keyword          User  \\\n",
       "0  2d animation  AnimatorsPal   \n",
       "1  2d animation    SirFowlman   \n",
       "2  2d animation   cadetcollar   \n",
       "3  2d animation      _Fungai_   \n",
       "4  2d animation      peridopp   \n",
       "\n",
       "                                               Tweet Language        Time  \\\n",
       "0  RT AnimationVFXJob Marvel Streaming Production...       en  2022-03-21   \n",
       "1  RT OleLoken I drew a lady on a vespa then i dr...       en  2022-03-21   \n",
       "2  this 100 true lol as an animation student i wa...       en  2022-03-21   \n",
       "3  RT animationjobs 2D Production Supervisor job ...       en  2022-03-21   \n",
       "4  RT KoalaDingoLabo The koala facing the frogsga...       en  2022-03-21   \n",
       "\n",
       "  User Location                                            Hashtag  Polarity  \\\n",
       "0        Berlin  ['freelanceremotecontractworkfromhome', 'produ...   neutral   \n",
       "1     Australia                              ['2d', '2danimation']  positive   \n",
       "2  she/her | 22                                                 []  positive   \n",
       "3           NaN                                                 []   neutral   \n",
       "4      Scotland  ['gamedev', 'madewithunity', 'unity3d', 'metro...   neutral   \n",
       "\n",
       "   Likes  Retweet  Sentiment  \n",
       "0    0.0      1.0   0.000000  \n",
       "1    0.0     50.0   0.750000  \n",
       "2    5.0      0.0   0.359524  \n",
       "3    0.0      1.0   0.000000  \n",
       "4    0.0     14.0   0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.newUnion()\n",
    "dm.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animation</td>\n",
       "      <td>70106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anime</td>\n",
       "      <td>56370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Titan</td>\n",
       "      <td>40059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Attack</td>\n",
       "      <td>38897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>34852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157209</th>\n",
       "      <td>‡∏™‡∏ß‡∏°‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157210</th>\n",
       "      <td>929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157211</th>\n",
       "      <td>‡∏ö‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157212</th>\n",
       "      <td>‡∏û‡∏¥‡∏ó‡∏±‡∏Å‡∏©‡πå</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157213</th>\n",
       "      <td>‡∏î‡∏π‡∏ï‡∏±‡∏ß</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157214 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Count\n",
       "0       animation  70106\n",
       "1           anime  56370\n",
       "2           Titan  40059\n",
       "3          Attack  38897\n",
       "4             amp  34852\n",
       "...           ...    ...\n",
       "157209   ‡∏™‡∏ß‡∏°‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó      1\n",
       "157210        929      1\n",
       "157211    ‡∏ö‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤      1\n",
       "157212    ‡∏û‡∏¥‡∏ó‡∏±‡∏Å‡∏©‡πå      1\n",
       "157213      ‡∏î‡∏π‡∏ï‡∏±‡∏ß      1\n",
       "\n",
       "[157214 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.collectwords(dm.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start saving @ 21:22:59\n",
      "save old key\n",
      "save file comp\n",
      "save complete @ 21:23:01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>uuzilla</td>\n",
       "      <td>RT museacgth SPY X FAMILY 9 2200</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>arxxct_</td>\n",
       "      <td>RT jamthofficial Spy x Family 9 Nerflix JapanA...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>/ ‚õìÔ∏è</td>\n",
       "      <td>['JapanAnimeMovieTha']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>OwiDkami</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>tob4ias</td>\n",
       "      <td>RT animetvjp Character VisualsSPY x FAMILY Ani...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>hewkapii</td>\n",
       "      <td>RT jamthofficial Spy x Family 9 Nerflix JapanA...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>„ÄÅ‡∏°‡∏∏‡πà / #‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏°.112</td>\n",
       "      <td>['JapanAnimeMovieTha']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>_assckerman</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>surlysagittari</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>aintapril</td>\n",
       "      <td>RT animetvjp Character VisualsSPY x FAMILY Ani...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>capyper land</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>kaitogaming1412</td>\n",
       "      <td>AniTrendz Looking forward for spy x family to ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>yoosunfish</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>she/her | 20</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>aamandab_d</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>1OPITER</td>\n",
       "      <td>OOMFS HAS ANYONE READ SPY X FAMILY YET AND DO ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>ÂõΩÂ¥©„Åó„ÅÆÂøÉ</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>HoneyToast_____</td>\n",
       "      <td>RT myanimelist News Spy x Family unveils chara...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>Î∞±ÌòÑÎ∞ñÏóê ÏóÜÏñ¥</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>LuiisM_18</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>reddy_abcde</td>\n",
       "      <td>RT jamthofficial Spy x Family 9 Nerflix JapanA...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['JapanAnimeMovieTha']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>graydali</td>\n",
       "      <td>RT myanimelist News Spy x Family unveils chara...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>she/her 24, Europe</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Vxe_1649</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>20 ‚ô°</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Tarik82414154</td>\n",
       "      <td>RT SeasonalOPs SPY x FAMILY OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Punnakun4</td>\n",
       "      <td>RT museacgth SPY X FAMILY 9 2200</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>aarsi_3</td>\n",
       "      <td>RT animetvjp Character VisualsSPY x FAMILY Ani...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>lesspork</td>\n",
       "      <td>RT jamthofficial Spy x Family 9 Nerflix JapanA...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['JapanAnimeMovieTha']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>kaitogaming1412</td>\n",
       "      <td>RT SpyFamilyShots 19 days until Spy x Family</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>SilverWield</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>living rent free in your head</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>maintaytawan</td>\n",
       "      <td>Spy x family Netflix</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>MoreClaymore</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>dugong_fu</td>\n",
       "      <td>RT SeasonalOPs SPY x FAMILY OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>En d√©pression le retour</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>MoonchildSasuke</td>\n",
       "      <td>RT hourlysxf SPY X FAMILY OPENING</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>she/her |  21 | üçÖüç•</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>ladyalitacastle</td>\n",
       "      <td>RT LeoSxF Spy x Familys episode 2 is coming ou...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>caracas</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>TunaMayoTakana</td>\n",
       "      <td>RT SeasonalOPs SPY x FAMILY OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>GrandpaTurbo</td>\n",
       "      <td>RT SeasonalOPs SPY x FAMILY OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>mariawithIuv</td>\n",
       "      <td>RT SpyFamilyManga Spy x Family Opening Mixed N...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>latinowhatfuck</td>\n",
       "      <td>RT soukatsu heres the Spy x Family OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Portgas_D_Gab</td>\n",
       "      <td>RT hiyorigatinha artes oficias de spy x family...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>he/him ‚ô§18y</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>satourgojo</td>\n",
       "      <td>RT dailySpyFamily SPY X FAMILY OPENING</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td>they she 20</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Sakutax0</td>\n",
       "      <td>SPY X FAMILY OPENING</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>Gabzilla_z</td>\n",
       "      <td>RT SeasonalOPs SPY x FAMILY OP</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-16</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spy x family</td>\n",
       "      <td>fysrna</td>\n",
       "      <td>RT Crunchyroll SPY x FAMILY arrives on Crunchy...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Keyword             User  \\\n",
       "19  spy x family          uuzilla   \n",
       "17  spy x family          arxxct_   \n",
       "7   spy x family         OwiDkami   \n",
       "6   spy x family          tob4ias   \n",
       "5   spy x family         hewkapii   \n",
       "4   spy x family      _assckerman   \n",
       "3   spy x family   surlysagittari   \n",
       "2   spy x family        aintapril   \n",
       "8   spy x family  kaitogaming1412   \n",
       "0   spy x family       yoosunfish   \n",
       "1   spy x family       aamandab_d   \n",
       "14  spy x family          1OPITER   \n",
       "13  spy x family  HoneyToast_____   \n",
       "15  spy x family        LuiisM_18   \n",
       "11  spy x family      reddy_abcde   \n",
       "10  spy x family         graydali   \n",
       "9   spy x family         Vxe_1649   \n",
       "10  spy x family    Tarik82414154   \n",
       "16  spy x family        Punnakun4   \n",
       "18  spy x family          aarsi_3   \n",
       "20  spy x family         lesspork   \n",
       "21  spy x family  kaitogaming1412   \n",
       "22  spy x family      SilverWield   \n",
       "23  spy x family     maintaytawan   \n",
       "24  spy x family     MoreClaymore   \n",
       "0   spy x family        dugong_fu   \n",
       "7   spy x family  MoonchildSasuke   \n",
       "2   spy x family  ladyalitacastle   \n",
       "3   spy x family   TunaMayoTakana   \n",
       "4   spy x family     GrandpaTurbo   \n",
       "5   spy x family     mariawithIuv   \n",
       "6   spy x family   latinowhatfuck   \n",
       "8   spy x family    Portgas_D_Gab   \n",
       "9   spy x family       satourgojo   \n",
       "1   spy x family         Sakutax0   \n",
       "11  spy x family       Gabzilla_z   \n",
       "12  spy x family           fysrna   \n",
       "\n",
       "                                                Tweet Language        Time  \\\n",
       "19                   RT museacgth SPY X FAMILY 9 2200       th  2022-03-26   \n",
       "17  RT jamthofficial Spy x Family 9 Nerflix JapanA...       th  2022-03-26   \n",
       "7   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "6   RT animetvjp Character VisualsSPY x FAMILY Ani...       en  2022-03-26   \n",
       "5   RT jamthofficial Spy x Family 9 Nerflix JapanA...       th  2022-03-26   \n",
       "4   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "3   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "2   RT animetvjp Character VisualsSPY x FAMILY Ani...       en  2022-03-26   \n",
       "8   AniTrendz Looking forward for spy x family to ...       en  2022-03-26   \n",
       "0   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "1   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "14  OOMFS HAS ANYONE READ SPY X FAMILY YET AND DO ...       en  2022-03-26   \n",
       "13  RT myanimelist News Spy x Family unveils chara...       en  2022-03-26   \n",
       "15  RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "11  RT jamthofficial Spy x Family 9 Nerflix JapanA...       th  2022-03-26   \n",
       "10  RT myanimelist News Spy x Family unveils chara...       en  2022-03-26   \n",
       "9   RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "10                     RT SeasonalOPs SPY x FAMILY OP       en  2022-04-16   \n",
       "16                   RT museacgth SPY X FAMILY 9 2200       th  2022-03-26   \n",
       "18  RT animetvjp Character VisualsSPY x FAMILY Ani...       en  2022-03-26   \n",
       "20  RT jamthofficial Spy x Family 9 Nerflix JapanA...       th  2022-03-26   \n",
       "21       RT SpyFamilyShots 19 days until Spy x Family       en  2022-03-26   \n",
       "22  RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "23                               Spy x family Netflix       en  2022-03-26   \n",
       "24  RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "0                      RT SeasonalOPs SPY x FAMILY OP       en  2022-04-16   \n",
       "7                   RT hourlysxf SPY X FAMILY OPENING       en  2022-04-16   \n",
       "2   RT LeoSxF Spy x Familys episode 2 is coming ou...       en  2022-04-16   \n",
       "3                      RT SeasonalOPs SPY x FAMILY OP       en  2022-04-16   \n",
       "4                      RT SeasonalOPs SPY x FAMILY OP       en  2022-04-16   \n",
       "5   RT SpyFamilyManga Spy x Family Opening Mixed N...       en  2022-04-16   \n",
       "6               RT soukatsu heres the Spy x Family OP       en  2022-04-16   \n",
       "8   RT hiyorigatinha artes oficias de spy x family...       en  2022-04-16   \n",
       "9              RT dailySpyFamily SPY X FAMILY OPENING       en  2022-04-16   \n",
       "1                                SPY X FAMILY OPENING       en  2022-04-16   \n",
       "11                     RT SeasonalOPs SPY x FAMILY OP       en  2022-04-16   \n",
       "12  RT Crunchyroll SPY x FAMILY arrives on Crunchy...       en  2022-03-26   \n",
       "\n",
       "                    User Location                 Hashtag  Polarity  Likes  \\\n",
       "19                            NaN                      []       NaN    0.0   \n",
       "17                           / ‚õìÔ∏è  ['JapanAnimeMovieTha']       NaN    0.0   \n",
       "7                             NaN                      []   neutral    0.0   \n",
       "6                             NaN                      []   neutral    0.0   \n",
       "5             „ÄÅ‡∏°‡∏∏‡πà / #‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏°.112  ['JapanAnimeMovieTha']       NaN    0.0   \n",
       "4                             NaN                      []   neutral    0.0   \n",
       "3                             NaN                      []   neutral    0.0   \n",
       "2                    capyper land                      []   neutral    0.0   \n",
       "8                             NaN                      []  positive    0.0   \n",
       "0                    she/her | 20                      []   neutral    0.0   \n",
       "1                             NaN                      []   neutral    0.0   \n",
       "14                          ÂõΩÂ¥©„Åó„ÅÆÂøÉ                      []   neutral    0.0   \n",
       "13                        Î∞±ÌòÑÎ∞ñÏóê ÏóÜÏñ¥                      []   neutral    0.0   \n",
       "15                            NaN                      []   neutral    0.0   \n",
       "11                            NaN  ['JapanAnimeMovieTha']       NaN    0.0   \n",
       "10             she/her 24, Europe                      []   neutral    0.0   \n",
       "9                            20 ‚ô°                      []   neutral    0.0   \n",
       "10                                                     []   neutral    0.0   \n",
       "16                            NaN                      []       NaN    0.0   \n",
       "18                            NaN                      []   neutral    0.0   \n",
       "20                            NaN  ['JapanAnimeMovieTha']       NaN    0.0   \n",
       "21                            NaN                      []   neutral    0.0   \n",
       "22  living rent free in your head                      []   neutral    0.0   \n",
       "23                            NaN                      []   neutral    0.0   \n",
       "24                            NaN                      []   neutral    0.0   \n",
       "0        En d√©pression le retour                       []   neutral    0.0   \n",
       "7              she/her |  21 | üçÖüç•                      []   neutral    0.0   \n",
       "2                         caracas                      []   neutral    0.0   \n",
       "3                                                      []   neutral    0.0   \n",
       "4                                                      []   neutral    0.0   \n",
       "5                                                      []   neutral    0.0   \n",
       "6                                                      []   neutral    0.0   \n",
       "8                     he/him ‚ô§18y                      []   neutral    0.0   \n",
       "9                     they she 20                      []   neutral    0.0   \n",
       "1                                                      []   neutral    0.0   \n",
       "11                                                     []   neutral    0.0   \n",
       "12                            NaN                      []   neutral    0.0   \n",
       "\n",
       "    Retweet  Sentiment  \n",
       "19    202.0        0.0  \n",
       "17    455.0        0.0  \n",
       "7    1720.0        0.0  \n",
       "6     804.0        0.0  \n",
       "5     455.0        0.0  \n",
       "4    1720.0        0.0  \n",
       "3    1720.0        0.0  \n",
       "2     804.0        0.0  \n",
       "8       0.0        0.5  \n",
       "0    1720.0        0.0  \n",
       "1    1720.0        0.0  \n",
       "14      0.0        0.0  \n",
       "13    139.0        0.0  \n",
       "15   1720.0        0.0  \n",
       "11    455.0        0.0  \n",
       "10    139.0        0.0  \n",
       "9    1720.0        0.0  \n",
       "10    461.0        0.0  \n",
       "16    202.0        0.0  \n",
       "18    804.0        0.0  \n",
       "20    455.0        0.0  \n",
       "21    314.0        0.0  \n",
       "22   1720.0        0.0  \n",
       "23      0.0        0.0  \n",
       "24   1720.0        0.0  \n",
       "0     461.0        0.0  \n",
       "7      73.0        0.0  \n",
       "2      94.0        0.0  \n",
       "3     461.0        0.0  \n",
       "4     461.0        0.0  \n",
       "5     106.0        0.0  \n",
       "6      73.0        0.0  \n",
       "8     993.0        0.0  \n",
       "9      33.0        0.0  \n",
       "1       0.0        0.0  \n",
       "11    461.0        0.0  \n",
       "12   1720.0        0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tws = Twitter_Scrap()\n",
    "tws.setdataframe(dm.df)\n",
    "tws.searchkeys(['spy x family'],'real','2022-4-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"collectkeys\"\n",
    "path = str(folder+'/'+'pixarr')\n",
    "os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.collectfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path=os.getcwd()\n",
    "shutil.rmtree(path+'//collectkeys//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setnewDF(df1)\n",
    "dm.getperiod('2022-03-21','2022-03-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setdefaultDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dm.collectword()[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dm.collectword()[:100],columns=['Word','Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)\n",
    "dm.formatdatetime('Time')\n",
    "print(dm.df['Time'].min().strftime('%Y/%m/%d'))\n",
    "print(dm.df['Time'].max().strftime('%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','‡∏ï‡πà‡∏≤‡∏á‡πÇ‡∏•‡∏Å','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞','2d animation','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥','japan animation']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\"\n",
    "keyword = list(map(lambda x: x.lower(), keyword))\n",
    "keyword\n",
    "print(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweet_data_2732022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8116/3920850865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweet_data_2732022.csv'"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus import thai_stopwords\n",
    "th_stopwords = list(thai_stopwords())\n",
    "\n",
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['‡∏ï‡πà‡∏≤‡∏á‡πÇ‡∏•‡∏Å','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞'])]\n",
    "dff = dff.reset_index()##\n",
    "word = {}\n",
    "\n",
    "for index,row in dff.iterrows():##\n",
    "    if row['Language'] == 'en':\n",
    "        allwords = row['Tweet'].split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    elif row['Language'] == 'th':   #\n",
    "        allwords = word_tokenize(row['Tweet'], engine='newmm')  #\n",
    "        for w in allwords: \n",
    "            if w not in th_stopwords:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        pass\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.reset_index()\n",
    "for index,row in dff.iterrows():\n",
    "    print(row['Tweet'],row['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = '‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "df = dm.unionfile(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "folder = \"collectkeys\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for key in keys:\n",
    "    path = str(folder+'/'+key)\n",
    "    dff = df.loc[df['Keyword'].isin([key])]\n",
    "    days = list(set(dff['Time'].tolist()))\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for d in days:\n",
    "        dfff = dff.loc[dff['Time'].isin([d])]\n",
    "        dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

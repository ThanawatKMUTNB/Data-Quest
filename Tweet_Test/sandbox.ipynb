{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  \n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        params = {'text':text}\n",
    "        response = requests.get(self._url, headers=self._headers, params=params)\n",
    "        try:\n",
    "            polarity = str(response.json()['sentiment']['polarity'])\n",
    "        except (KeyError):\n",
    "            polarity = 'neutral'\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d') #dmY ทีหลัง\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        return self.df\n",
    "    \n",
    "    def setnewDF(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        self.df = self.unionfile(self.filenames)\n",
    "        return self.df\n",
    "\n",
    "    # def getperiod(self,since,until):  ####column for twitter\n",
    "    #     self.formatdatetime('Time')\n",
    "    #     self.df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "    #     if since == None and until != None:\n",
    "    #         mask = (self.df['Time']<=until)\n",
    "    #     elif since != None and until == None:\n",
    "    #         mask = (self.df['Time']>=since)\n",
    "    #     elif since != None and until != None:\n",
    "    #         mask = (self.df['Time']>=since) & (self.df['Time']<=until)\n",
    "    #     else:\n",
    "    #         return\n",
    "    #     #self.df = self.df.loc[mask]\n",
    "    #     return self.df.loc[mask]\n",
    "    \n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return\n",
    "        return dff.loc[mask]\n",
    "\n",
    "    # def getrowwithkeys(self,keys):              #type keys -> list\n",
    "    #     df = self.df\n",
    "    #     self.df = df.loc[df['Keyword'].isin(keys)]\n",
    "    #     self.df = self.df.loc[self.df['Keyword'].isin(keys)]\n",
    "    #     return self.df\n",
    "    \n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectword(self):            #before edit collect thai can not use\n",
    "        dataframe = self.df\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        word = {}\n",
    "        for i in dataframe['Tweet']:    #only tweet\n",
    "            if langdetect.detect(i) != 'th':\n",
    "                allwords = i.split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                allwords = word_tokenize(i, engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "        del word['RT']\n",
    "        del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        return sortword     #tuple in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animation</td>\n",
       "      <td>dialhforhero</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>An animation trailer x100 times better than mo...</td>\n",
       "      <td>2022-03-19 11:44:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animation</td>\n",
       "      <td>MaFt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@winstano My uncle @Billy_Allison did the anim...</td>\n",
       "      <td>2022-03-19 09:09:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animation</td>\n",
       "      <td>plushladyy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ghhh there was this animation about moon danci...</td>\n",
       "      <td>2022-03-19 09:39:41+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>animation</td>\n",
       "      <td>aeyvindr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I wonder how would the past me say seeing my d...</td>\n",
       "      <td>2022-03-19 12:14:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>zeze_luva</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The plot of \"I’ve Gone Viral Thanks to My Crus...</td>\n",
       "      <td>2022-03-19 15:58:17+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Worra_K</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT bbrinkk มีกิจกรรมฟินๆมาแนะนำ สาววายถูกใจสิ่...</td>\n",
       "      <td>2022-03-24 10:49:48+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['สาววายถ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>97.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>W3NY7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>2022-03-24 08:41:09+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>18 up /</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>nokkyhuhu</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT yalovejong เทรดแนะนำ BL ทั้งฟิคและนิยายมังง...</td>\n",
       "      <td>2022-03-24 04:51:04+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>ILYSB_I</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>2022-03-23 19:48:49+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>littleslothseiy</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...</td>\n",
       "      <td>2022-03-26 14:30:19+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110758 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keyword             User  Retweet  Likes  \\\n",
       "0       animation     dialhforhero      0.0    0.0   \n",
       "1       animation             MaFt      0.0    0.0   \n",
       "2       animation       plushladyy      0.0    0.0   \n",
       "3       animation         aeyvindr      0.0    0.0   \n",
       "4       animation        zeze_luva      0.0    0.0   \n",
       "...           ...              ...      ...    ...   \n",
       "4898  อนิเมะแนะนำ          Worra_K     41.0    0.0   \n",
       "4899  อนิเมะแนะนำ            W3NY7     33.0    0.0   \n",
       "4900  อนิเมะแนะนำ        nokkyhuhu     14.0    0.0   \n",
       "4901  อนิเมะแนะนำ          ILYSB_I     33.0    0.0   \n",
       "4902  อนิเมะแนะนำ  littleslothseiy   1006.0    0.0   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "0     An animation trailer x100 times better than mo...   \n",
       "1     @winstano My uncle @Billy_Allison did the anim...   \n",
       "2     Ghhh there was this animation about moon danci...   \n",
       "3     I wonder how would the past me say seeing my d...   \n",
       "4     The plot of \"I’ve Gone Viral Thanks to My Crus...   \n",
       "...                                                 ...   \n",
       "4898  RT bbrinkk มีกิจกรรมฟินๆมาแนะนำ สาววายถูกใจสิ่...   \n",
       "4899  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...   \n",
       "4900  RT yalovejong เทรดแนะนำ BL ทั้งฟิคและนิยายมังง...   \n",
       "4901  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...   \n",
       "4902  RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...   \n",
       "\n",
       "                           Time Language      User Location      Hashtag  \\\n",
       "0     2022-03-19 11:44:27+00:00      NaN                NaN          NaN   \n",
       "1     2022-03-19 09:09:22+00:00      NaN                NaN          NaN   \n",
       "2     2022-03-19 09:39:41+00:00      NaN                NaN          NaN   \n",
       "3     2022-03-19 12:14:58+00:00      NaN                NaN          NaN   \n",
       "4     2022-03-19 15:58:17+00:00      NaN                NaN          NaN   \n",
       "...                         ...      ...                ...          ...   \n",
       "4898  2022-03-24 10:49:48+00:00       th                NaN  ['สาววายถ']   \n",
       "4899  2022-03-24 08:41:09+00:00       th           18 up /    ['แนะนำอ']   \n",
       "4900  2022-03-24 04:51:04+00:00       th  Bangkok, Thailand           []   \n",
       "4901  2022-03-23 19:48:49+00:00       th                NaN   ['แนะนำอ']   \n",
       "4902  2022-03-26 14:30:19+00:00       th    𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻           []   \n",
       "\n",
       "      Polarity  Sentiment  \n",
       "0          NaN        NaN  \n",
       "1          NaN        NaN  \n",
       "2          NaN        NaN  \n",
       "3          NaN        NaN  \n",
       "4          NaN        NaN  \n",
       "...        ...        ...  \n",
       "4898  positive      97.30  \n",
       "4899  positive      66.67  \n",
       "4900  negative      66.67  \n",
       "4901  positive      66.67  \n",
       "4902  positive      66.67  \n",
       "\n",
       "[110758 rows x 11 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dff = dm.unionfile(filename)\n",
    "#dm.unionfile(['tweet_data_2732022.csv'])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Shounen_w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@seongisdaddy never gonna happen ue</td>\n",
       "      <td>2022-03-19 08:17:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24209</th>\n",
       "      <td>shounen</td>\n",
       "      <td>ipqiyv88</td>\n",
       "      <td>761.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...</td>\n",
       "      <td>2022-03-25 13:01:30+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24210</th>\n",
       "      <td>shounen</td>\n",
       "      <td>youtaroyoujo</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT RottingVale Had a very long and funny conve...</td>\n",
       "      <td>2022-03-25 05:22:26+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24211</th>\n",
       "      <td>shounen</td>\n",
       "      <td>DiegoHdzF</td>\n",
       "      <td>3778.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-25 07:24:29+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Monterrey</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24212</th>\n",
       "      <td>shounen</td>\n",
       "      <td>costa6770l</td>\n",
       "      <td>3587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-25 06:13:29+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20102</th>\n",
       "      <td>shounen</td>\n",
       "      <td>bellezzadellunv</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24 16:26:52+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>ist</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20103</th>\n",
       "      <td>shounen</td>\n",
       "      <td>ahhkeeh</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24 16:26:56+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20104</th>\n",
       "      <td>shounen</td>\n",
       "      <td>chiungwei17</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24 16:27:04+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20106</th>\n",
       "      <td>shounen</td>\n",
       "      <td>MENG5533</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT SekiraNFT SHOUNEN X SKIRAPleased to announc...</td>\n",
       "      <td>2022-03-24 16:27:21+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>johor</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>shounen</td>\n",
       "      <td>febryantop</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...</td>\n",
       "      <td>2022-03-26 16:54:52+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10639 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Keyword             User  Retweet  Likes  \\\n",
       "2006   shounen        Shounen_w      0.0    1.0   \n",
       "24209  shounen         ipqiyv88    761.0    0.0   \n",
       "24210  shounen     youtaroyoujo     15.0    0.0   \n",
       "24211  shounen        DiegoHdzF   3778.0    0.0   \n",
       "24212  shounen       costa6770l   3587.0    0.0   \n",
       "...        ...              ...      ...    ...   \n",
       "20102  shounen  bellezzadellunv   2236.0    0.0   \n",
       "20103  shounen          ahhkeeh   2236.0    0.0   \n",
       "20104  shounen      chiungwei17   2236.0    0.0   \n",
       "20106  shounen         MENG5533    318.0    0.0   \n",
       "4048   shounen       febryantop   2128.0    0.0   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "2006                 @seongisdaddy never gonna happen ue   \n",
       "24209  RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...   \n",
       "24210  RT RottingVale Had a very long and funny conve...   \n",
       "24211  RT GodJiraslove WL GIVEAWAYWe are giving away ...   \n",
       "24212  RT GodJiraslove WL GIVEAWAYWe are giving away ...   \n",
       "...                                                  ...   \n",
       "20102  RT GodJiraslove WL GIVEAWAYWe are giving away ...   \n",
       "20103  RT GodJiraslove WL GIVEAWAYWe are giving away ...   \n",
       "20104  RT GodJiraslove WL GIVEAWAYWe are giving away ...   \n",
       "20106  RT SekiraNFT SHOUNEN X SKIRAPleased to announc...   \n",
       "4048   RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...   \n",
       "\n",
       "                            Time Language User Location Hashtag  Polarity  \\\n",
       "2006   2022-03-19 08:17:18+00:00      NaN           NaN     NaN       NaN   \n",
       "24209  2022-03-25 13:01:30+00:00       en           NaN      []   neutral   \n",
       "24210  2022-03-25 05:22:26+00:00       en           NaN      []  positive   \n",
       "24211  2022-03-25 07:24:29+00:00       en     Monterrey      []   neutral   \n",
       "24212  2022-03-25 06:13:29+00:00       en           NaN      []   neutral   \n",
       "...                          ...      ...           ...     ...       ...   \n",
       "20102  2022-03-24 16:26:52+00:00       en           ist      []   neutral   \n",
       "20103  2022-03-24 16:26:56+00:00       en           NaN      []   neutral   \n",
       "20104  2022-03-24 16:27:04+00:00       en           NaN      []   neutral   \n",
       "20106  2022-03-24 16:27:21+00:00       en         johor      []  positive   \n",
       "4048   2022-03-26 16:54:52+00:00       en           NaN      []   neutral   \n",
       "\n",
       "       Sentiment  \n",
       "2006         NaN  \n",
       "24209       0.00  \n",
       "24210       0.02  \n",
       "24211       0.00  \n",
       "24212       0.00  \n",
       "...          ...  \n",
       "20102       0.00  \n",
       "20103       0.00  \n",
       "20104       0.00  \n",
       "20106       0.50  \n",
       "4048        0.00  \n",
       "\n",
       "[10639 rows x 11 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>shounen</td>\n",
       "      <td>HipHopBigWin</td>\n",
       "      <td>6371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT NFTSHOUNEN Playful perception of everyday o...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>en</td>\n",
       "      <td>tg- februarywinz</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>shounen</td>\n",
       "      <td>0xpickawpickr</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT NFTSHOUNEN Playful perception of everyday o...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>en</td>\n",
       "      <td>give away hunter （＾ω＾）</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>shounen</td>\n",
       "      <td>pilihakucityx</td>\n",
       "      <td>5849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT NFTSHOUNEN Playful perception of everyday o...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>en</td>\n",
       "      <td>Central Java, Indonesia</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Shounen_w</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT THEMAzine Contributor signups are open for ...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>en</td>\n",
       "      <td>V O I D</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>shounen</td>\n",
       "      <td>BnR_Kasep</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT NFTSHOUNEN Playful perception of everyday o...</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>en</td>\n",
       "      <td>DKI Jakarta, Indonesia</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22048</th>\n",
       "      <td>shounen</td>\n",
       "      <td>JassAnn6</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22071</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Danieldew101</td>\n",
       "      <td>1263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>en</td>\n",
       "      <td>USA</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22099</th>\n",
       "      <td>shounen</td>\n",
       "      <td>CrickHelvey</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat...</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>en</td>\n",
       "      <td>thanh hóa</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22092</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Bbbbbbssssss222</td>\n",
       "      <td>433.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22086</th>\n",
       "      <td>shounen</td>\n",
       "      <td>mnl11_</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>en</td>\n",
       "      <td>mnl11.eth</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8244 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Keyword             User  Retweet  Likes  \\\n",
       "2892   shounen     HipHopBigWin   6371.0    0.0   \n",
       "2893   shounen    0xpickawpickr   5740.0    0.0   \n",
       "2894   shounen    pilihakucityx   5849.0    0.0   \n",
       "2895   shounen        Shounen_w      8.0    0.0   \n",
       "2896   shounen        BnR_Kasep   5805.0    0.0   \n",
       "...        ...              ...      ...    ...   \n",
       "22048  shounen         JassAnn6    422.0    0.0   \n",
       "22071  shounen     Danieldew101   1263.0    0.0   \n",
       "22099  shounen      CrickHelvey   1195.0    0.0   \n",
       "22092  shounen  Bbbbbbssssss222    433.0    0.0   \n",
       "22086  shounen           mnl11_    410.0    0.0   \n",
       "\n",
       "                                                   Tweet       Time Language  \\\n",
       "2892   RT NFTSHOUNEN Playful perception of everyday o... 2022-03-21       en   \n",
       "2893   RT NFTSHOUNEN Playful perception of everyday o... 2022-03-21       en   \n",
       "2894   RT NFTSHOUNEN Playful perception of everyday o... 2022-03-21       en   \n",
       "2895   RT THEMAzine Contributor signups are open for ... 2022-03-21       en   \n",
       "2896   RT NFTSHOUNEN Playful perception of everyday o... 2022-03-21       en   \n",
       "...                                                  ...        ...      ...   \n",
       "22048  RT WGMIIndustries WGMI Industries x SHOUNEN To... 2022-03-25       en   \n",
       "22071  RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat... 2022-03-25       en   \n",
       "22099  RT BroskeesNFTs BROSKEES x SHOUNEN To celebrat... 2022-03-25       en   \n",
       "22092  RT WGMIIndustries WGMI Industries x SHOUNEN To... 2022-03-25       en   \n",
       "22086  RT WGMIIndustries WGMI Industries x SHOUNEN To... 2022-03-25       en   \n",
       "\n",
       "                 User Location Hashtag  Polarity  Sentiment  \n",
       "2892          tg- februarywinz      []  positive   0.333333  \n",
       "2893    give away hunter （＾ω＾）      []  positive   0.333333  \n",
       "2894   Central Java, Indonesia      []  positive   0.333333  \n",
       "2895                   V O I D      []  positive   0.291667  \n",
       "2896    DKI Jakarta, Indonesia      []  positive   0.333333  \n",
       "...                        ...     ...       ...        ...  \n",
       "22048                  Twitter      []   neutral   0.000000  \n",
       "22071                      USA      []   neutral   0.000000  \n",
       "22099                thanh hóa      []   neutral   0.000000  \n",
       "22092                      NaN      []   neutral   0.000000  \n",
       "22086                mnl11.eth      []   neutral   0.000000  \n",
       "\n",
       "[8244 rows x 11 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.setnewDF(df1)\n",
    "dm.getperiod('2022-03-21','2022-03-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animation</td>\n",
       "      <td>dialhforhero</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>An animation trailer x100 times better than mo...</td>\n",
       "      <td>2022-03-19 11:44:27+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animation</td>\n",
       "      <td>MaFt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@winstano My uncle @Billy_Allison did the anim...</td>\n",
       "      <td>2022-03-19 09:09:22+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animation</td>\n",
       "      <td>plushladyy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ghhh there was this animation about moon danci...</td>\n",
       "      <td>2022-03-19 09:39:41+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>animation</td>\n",
       "      <td>aeyvindr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I wonder how would the past me say seeing my d...</td>\n",
       "      <td>2022-03-19 12:14:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animation</td>\n",
       "      <td>zeze_luva</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The plot of \"I’ve Gone Viral Thanks to My Crus...</td>\n",
       "      <td>2022-03-19 15:58:17+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Worra_K</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT bbrinkk มีกิจกรรมฟินๆมาแนะนำ สาววายถูกใจสิ่...</td>\n",
       "      <td>2022-03-24 10:49:48+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['สาววายถ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>97.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>W3NY7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>2022-03-24 08:41:09+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>18 up /</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>nokkyhuhu</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT yalovejong เทรดแนะนำ BL ทั้งฟิคและนิยายมังง...</td>\n",
       "      <td>2022-03-24 04:51:04+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>ILYSB_I</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...</td>\n",
       "      <td>2022-03-23 19:48:49+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>littleslothseiy</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...</td>\n",
       "      <td>2022-03-26 14:30:19+00:00</td>\n",
       "      <td>th</td>\n",
       "      <td>𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110758 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keyword             User  Retweet  Likes  \\\n",
       "0       animation     dialhforhero      0.0    0.0   \n",
       "1       animation             MaFt      0.0    0.0   \n",
       "2       animation       plushladyy      0.0    0.0   \n",
       "3       animation         aeyvindr      0.0    0.0   \n",
       "4       animation        zeze_luva      0.0    0.0   \n",
       "...           ...              ...      ...    ...   \n",
       "4898  อนิเมะแนะนำ          Worra_K     41.0    0.0   \n",
       "4899  อนิเมะแนะนำ            W3NY7     33.0    0.0   \n",
       "4900  อนิเมะแนะนำ        nokkyhuhu     14.0    0.0   \n",
       "4901  อนิเมะแนะนำ          ILYSB_I     33.0    0.0   \n",
       "4902  อนิเมะแนะนำ  littleslothseiy   1006.0    0.0   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "0     An animation trailer x100 times better than mo...   \n",
       "1     @winstano My uncle @Billy_Allison did the anim...   \n",
       "2     Ghhh there was this animation about moon danci...   \n",
       "3     I wonder how would the past me say seeing my d...   \n",
       "4     The plot of \"I’ve Gone Viral Thanks to My Crus...   \n",
       "...                                                 ...   \n",
       "4898  RT bbrinkk มีกิจกรรมฟินๆมาแนะนำ สาววายถูกใจสิ่...   \n",
       "4899  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...   \n",
       "4900  RT yalovejong เทรดแนะนำ BL ทั้งฟิคและนิยายมังง...   \n",
       "4901  RT todojamy เธรดแนะนำรีวิว อนิเมะกีฬาที่เราเคย...   \n",
       "4902  RT MWN ถ้าใครชอบดูอนิเมะแนวแฟนตาซี เหนือธรรมชา...   \n",
       "\n",
       "                           Time Language      User Location      Hashtag  \\\n",
       "0     2022-03-19 11:44:27+00:00      NaN                NaN          NaN   \n",
       "1     2022-03-19 09:09:22+00:00      NaN                NaN          NaN   \n",
       "2     2022-03-19 09:39:41+00:00      NaN                NaN          NaN   \n",
       "3     2022-03-19 12:14:58+00:00      NaN                NaN          NaN   \n",
       "4     2022-03-19 15:58:17+00:00      NaN                NaN          NaN   \n",
       "...                         ...      ...                ...          ...   \n",
       "4898  2022-03-24 10:49:48+00:00       th                NaN  ['สาววายถ']   \n",
       "4899  2022-03-24 08:41:09+00:00       th           18 up /    ['แนะนำอ']   \n",
       "4900  2022-03-24 04:51:04+00:00       th  Bangkok, Thailand           []   \n",
       "4901  2022-03-23 19:48:49+00:00       th                NaN   ['แนะนำอ']   \n",
       "4902  2022-03-26 14:30:19+00:00       th    𝚖𝚊𝚔𝚗𝚊𝚎 𝚕𝚒𝚗𝚎 🐰🐣🐻           []   \n",
       "\n",
       "      Polarity  Sentiment  \n",
       "0          NaN        NaN  \n",
       "1          NaN        NaN  \n",
       "2          NaN        NaN  \n",
       "3          NaN        NaN  \n",
       "4          NaN        NaN  \n",
       "...        ...        ...  \n",
       "4898  positive      97.30  \n",
       "4899  positive      66.67  \n",
       "4900  negative      66.67  \n",
       "4901  positive      66.67  \n",
       "4902  positive      66.67  \n",
       "\n",
       "[110758 rows x 11 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.setdefaultDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13516/166729799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13516/3650405174.py\u001b[0m in \u001b[0;36mcollectword\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m#only tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mlangdetect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'th'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[0mallwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mallwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langdetect\\detector_factory.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_factory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langdetect\\detector.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         '''\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langdetect\\detector.py\u001b[0m in \u001b[0;36mget_probabilities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlangprob\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_detect_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlangprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langdetect\\detector.py\u001b[0m in \u001b[0;36m_detect_block\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_lang_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_normalize_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCONV_THRESHOLD\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_LIMIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\langdetect\\detector.py\u001b[0m in \u001b[0;36m_update_lang_prob\u001b[1;34m(self, prob, word, alpha)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBASE_FREQ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mprob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlang_prob_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for word in dm.collectword()[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','ต่างโลก','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','อนิเมะ','2d animation','อนิเมะแนะนำ','japan animation']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022_1.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['pixar','อนิเมะ'])]\n",
    "word = {}\n",
    "\n",
    "for i in dff['Tweet']:\n",
    "    if langdetect.detect(i) != 'th':\n",
    "        allwords = i.split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        allwords = word_tokenize(i, engine='newmm')\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

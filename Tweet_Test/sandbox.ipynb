{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "import string\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect complete\n"
     ]
    }
   ],
   "source": [
    "# #tweet_data.csv to keyword files\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# start = 0\n",
    "# filenames = glob.glob(str(str(os.getcwd())+\"\\\\Data\\\\*.csv\"))\n",
    "# for file in filenames:\n",
    "#     df1 = pd.read_csv(file)\n",
    "#     if start != 0:\n",
    "#         df = pd.concat([df,df1])\n",
    "#         df.drop_duplicates(keep='last',inplace=True)\n",
    "#     else:\n",
    "#         df = df1\n",
    "#         start += 1\n",
    "# keys = list(set(df['Keyword'].tolist()))\n",
    "\n",
    "# df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "# keys = list(set(df['Keyword'].tolist()))\n",
    "# folder = \"collectkeys\"\n",
    "# if not os.path.exists(folder):\n",
    "#     os.mkdir(folder)    \n",
    "# for key in keys:\n",
    "#     path = str(folder+'/'+key)\n",
    "#     dff = df.loc[df['Keyword'].isin([key])]\n",
    "#     days = list(set(dff['Time'].tolist()))\n",
    "#     if not os.path.exists(path):\n",
    "#         os.mkdir(path)\n",
    "#     for d in days:\n",
    "#         dfff = dff.loc[dff['Time'].isin([d])]\n",
    "#         dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "# print('collect complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"kE7s0TJ00spb9kEPZ1BC7w8A16dpy8Cr\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "        self.keys = os.listdir(\"collectkeys\")\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        # print(text)\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        # print(text)\n",
    "        params = {'text':text}\n",
    "        # print(json.dumps(params, sort_keys=False, indent=4))\n",
    "        try:\n",
    "            response = requests.get(self._url, headers=self._headers, params=params)\n",
    "            try:\n",
    "                polarity = str(response.json()['sentiment']['polarity'])\n",
    "            except (KeyError):\n",
    "                polarity = 'neutral'\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            polarity = 'URI too long'\n",
    "            pass\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d')\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        self.keys = list(set(self.df['Keyword'].tolist()))\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def newUnion(self):\n",
    "        path=os.getcwd()\n",
    "        keys = []\n",
    "        start = 0\n",
    "        for f in glob.glob(path+'/collectkeys/*'):\n",
    "            keyname = os.path.split(f)[-1]\n",
    "            keys.append(keyname)\n",
    "        for k in keys:\n",
    "            for file in glob.glob(path+'/collectkeys/'+k+'/*.csv'):\n",
    "                if start == 0:\n",
    "                    self.df = pd.read_csv(file)\n",
    "                    start +=1\n",
    "                else:\n",
    "                    dff = pd.read_csv(file)\n",
    "                    self.df = pd.concat([self.df,dff])\n",
    "        self.keys = keys\n",
    "        #self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def setnewdf(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def concatfile(self,dataframe):\n",
    "        self.df = pd.concat([self.df,dataframe])\n",
    "        self.df.drop_duplicates(keep='last',inplace=True)\n",
    "        self.df.sort_values(by=['Keyword'],inplace=True)\n",
    "        self.formatdatetime('Time')\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        #self.df = self.unionfile(self.filenames)\n",
    "        self.df = self.newUnion()\n",
    "        return self.df\n",
    "    \n",
    "    def collectfile(self):\n",
    "        self.df[\"Time\"] = pd.to_datetime(self.df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "        keys = list(set(self.df['Keyword'].tolist()))\n",
    "        folder = \"collectkeys\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)    \n",
    "        for key in keys:\n",
    "            path = str(folder+'/'+key)\n",
    "            dff = self.df.loc[self.df['Keyword'].isin([key])]\n",
    "            days = list(set(dff['Time'].tolist()))\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            for d in days:\n",
    "                dfff = dff.loc[dff['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "        print('collect complete')\n",
    "\n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return dff\n",
    "        return dff.loc[mask]\n",
    "\n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectwords(self,dataframe):\n",
    "        #print(dataframe)\n",
    "        nltk.download('stopwords')          #important\n",
    "        dataframe = dataframe.reset_index()\n",
    "        th_stopwords = list(thai_stopwords())\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        en_stops.update(list(string.ascii_lowercase))\n",
    "        en_stops.update(list(string.ascii_uppercase))\n",
    "        word = {}\n",
    "        for index,row in dataframe.iterrows():    #only tweet\n",
    "            if row['Language'] == 'en':\n",
    "                allwords = str(row['Tweet']).split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            elif row['Language'] == 'th':\n",
    "                allwords = word_tokenize(row['Tweet'], engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in th_stopwords:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                pass\n",
    "        if 'RT' in word:\n",
    "            del word['RT']  #for twitter\n",
    "        if ' ' in word:\n",
    "            del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        worddf = pd.DataFrame(sortword,columns=['Word','Count'])\n",
    "        return worddf   #word dataframe\n",
    "        #return sortword     #tuple in list\n",
    "    \n",
    "    def deletekeyword(self,keyword):\n",
    "        path=os.getcwd()\n",
    "        for k  in keyword:\n",
    "            shutil.rmtree(path+'//collectkeys//'+k+'//')\n",
    "            self.keys.remove(k)\n",
    "            #self.df.drop(self.df[self.df['Keyword']==k].index,inplace = True)\n",
    "            self.df = self.newUnion()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter_Scrap:\n",
    "    def __init__(self):\n",
    "\n",
    "        #twitter api\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        #thai api\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"}\n",
    "\n",
    "        self.df = None\n",
    "        self.keys = []\n",
    "\n",
    "    def setdataframe(self,df):\n",
    "        self.df = df\n",
    "        self.keys = self.df['Keyword'].tolist()\n",
    "        self.keys = list(set(self.keys))\n",
    "\n",
    "    def getheader(self):\n",
    "        return self.df.columns.tolist()\n",
    "    \n",
    "    def getSentiment(self,text):\n",
    "\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "    \n",
    "    def extract_hashtags(self,text):\n",
    "\n",
    "        regex = \"#(\\w+)\" \n",
    "        hashtag_list = re.findall(regex, text)\n",
    "        return hashtag_list\n",
    "\n",
    "    def remove_url(self,txt):\n",
    "\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "    \n",
    "    def remove_url_th(self,txt):\n",
    "        return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())\n",
    "\n",
    "    def get_related_tweets(self,key_word,until):\n",
    "\n",
    "        tweet_keyword = []\n",
    "        twitter_users = []\n",
    "        twitter_users_location = []\n",
    "        tweet_hashtag = []\n",
    "        tweet_time = []\n",
    "        tweet_string = [] \n",
    "        tweet_countRT = []\n",
    "        tweet_fav = []\n",
    "        tweet_sentiment = []\n",
    "        tweet_polarity = []\n",
    "        tweet_language = []\n",
    "        for tweet in tw.Cursor(self._api.search_tweets,\n",
    "                                q=key_word,\n",
    "                                tweet_mode=\"extended\",\n",
    "                                until=until,\n",
    "                                include_entities=True).items(20):\n",
    "                                \n",
    "            if(tweet.lang == 'en'or tweet.lang == 'th'):\n",
    "                twitter_users.append(tweet.user.screen_name)\n",
    "                twitter_users_location.append(tweet.user.location)\n",
    "                tweet_time.append(tweet.created_at)\n",
    "                tweet_countRT.append(tweet.retweet_count)\n",
    "                tweet_fav.append(tweet.favorite_count)\n",
    "                tweet_keyword.append(key_word)\n",
    "                tweet_hashtag.append(str(self.extract_hashtags(tweet.full_text)))\n",
    "                tweet_language.append(tweet.lang)\n",
    "                if tweet.lang == 'en':\n",
    "                    tweet_string.append(self.remove_url(tweet.full_text))\n",
    "                    tweet_polarity.append(self.getSentiment(tweet.full_text))\n",
    "                    tweet_sentiment.append(TextBlob(tweet.full_text).sentiment.polarity)\n",
    "                elif tweet.lang == 'th':\n",
    "                    tweet_string.append(self.remove_url_th(tweet.full_text))\n",
    "                    text = re.sub(r'[%]',' ',tweet.full_text)\n",
    "                    params = {'text':text}\n",
    "                    response = requests.get(self._url, headers=self._headers, params=params)\n",
    "                    try:\n",
    "                        polarity = str(response.json()['sentiment']['polarity'])\n",
    "                        sentiment = str(response.json()['sentiment']['score'])\n",
    "                    except (KeyError):\n",
    "                        polarity = 'neutral'\n",
    "                        sentiment = 0\n",
    "                    tweet_polarity.append(polarity)\n",
    "                    tweet_sentiment.append(sentiment)\n",
    "\n",
    "        self.df = pd.DataFrame({'Keyword':tweet_keyword,'User':twitter_users,'Tweet': tweet_string,'Language':tweet_language, 'Time': tweet_time,'User Location':twitter_users_location,\n",
    "                            'Hashtag':tweet_hashtag,'Polarity':tweet_polarity,'Likes':tweet_fav,'Retweet':tweet_countRT,'Sentiment':tweet_sentiment})\n",
    "\n",
    "        \n",
    "        self.df['Time'] = pd.to_datetime(self.df['Time']).dt.strftime('%Y-%m-%d')\n",
    "        #self.df['Time'] = pd.to_datetime(self.df['Time'])\n",
    "        folder = \"collectkeys\"\n",
    "        path = str(folder+'/'+key_word)\n",
    "        days = list(set(self.df['Time'].tolist()))\n",
    "        if key_word not in self.keys:\n",
    "            \n",
    "            if not os.path.exists(path):    \n",
    "                os.mkdir(path)              #create direc for keyword\n",
    "            for d in days:\n",
    "                dfff = self.df.loc[self.df['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key_word+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "            print('save new file comp')\n",
    "        else:\n",
    "            print('save old key')\n",
    "            for d in days:\n",
    "                dfff = self.df.loc[self.df['Time'].isin([d])]\n",
    "                csvname = str(path+'/'+key_word+'_'+d+'.csv')\n",
    "                if csvname in glob.glob(str(str(os.getcwd())+\"\\\\collectkeys\\\\*.csv\")):\n",
    "                    olddf = pd.read_csv(csvname)\n",
    "                    newdf = pd.concat([dfff,olddf])\n",
    "                    newdf.drop_duplicates(keep='last',inplace=True)\n",
    "                    os.remove(csvname)\n",
    "                    newdf.to_csv(csvname,encoding='utf-8',index=False)\n",
    "                else:\n",
    "                    dfff.to_csv(csvname,encoding='utf-8',index=False)\n",
    "            print('save file comp')\n",
    "        return self.df\n",
    "\n",
    "    def savedata(self,keyword,until): #keyword is list\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print('\\nstart saving @',current_time)\n",
    "        #today = datetime.today()\n",
    "        #filename = str(\"tweet_data_\"+str(today.day)+str(today.month)+str(today.year)+\".csv\")\n",
    "\n",
    "        # if filename not in glob.glob(\"*.csv\"):\n",
    "        #     self.df = pd.DataFrame(columns=['Keyword','User','Tweet','Language','Time','User Location','Hashtag','Polarity','Likes','Retweet','Sentiment'])\n",
    "        # else:\n",
    "        #     self.df = pd.read_csv(filename)\n",
    "\n",
    "        for kw in keyword:\n",
    "            self.df = pd.concat([self.df,self.get_related_tweets(kw,until)])\n",
    "\n",
    "        self.df.drop_duplicates(keep='last',inplace=True)\n",
    "        self.df.sort_values(by=['Keyword'],inplace=True)\n",
    "        # if filename in glob.glob(\"*.csv\"):\n",
    "        #     os.remove(filename)\n",
    "        # self.df.to_csv(filename,encoding='utf-8',index=False)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print('save complete @',current_time)\n",
    "\n",
    "    def searchkeys(self,keyword,Ans,until):   #keyword's type is list\n",
    "        #print('keyword',keyword,'\\nkeys',self.keys,'\\nkeyword in keys?',keyword in self.keys)\n",
    "        # if \"\" in keyword:\n",
    "        #     return self.df\n",
    "        \n",
    "        #if len(keyword) > 1:            #>1 keyword\n",
    "        dhave = []\n",
    "        for key in keyword:\n",
    "            if key not in self.keys:\n",
    "                dhave.append(key)\n",
    "        print(keyword)\n",
    "        print(dhave)\n",
    "        if len(dhave) > 0:          #search new keyword\n",
    "            \n",
    "            self.savedata(dhave,until)\n",
    "            self.keys.extend(dhave)\n",
    "            newdf = self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            return newdf.progress_apply(lambda x: x)\n",
    "        elif Ans == \"real\":         #search old keys real time\n",
    "            self.savedata(keyword,until)\n",
    "            newdf = self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            return newdf.progress_apply(lambda x: x)\n",
    "        else:\n",
    "            newdf = self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "            return newdf.progress_apply(lambda x: x)\n",
    "        # elif keyword[0] in self.keys:   #1 key in old keys\n",
    "        #     if Ans == \"real\":\n",
    "        #         self.savedata(keyword,until)\n",
    "        #         return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "        #     else:\n",
    "        #         return self.df.loc[self.df['Keyword']==keyword[0]]\n",
    "        # else:              #1keyword (new)\n",
    "        #     if Ans == 'yes':            #new key 1 key\n",
    "                \n",
    "        #         self.savedata(keyword,until)\n",
    "        #         self.keys.extend(keyword)\n",
    "        #         return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "        #     # elif Ans == \"real\":\n",
    "        #     #     self.savedata(keyword,until)\n",
    "        #     #     return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])\n",
    "        #     else:\n",
    "        #         print('You select NO')\n",
    "        #         return self.df.loc[self.df['Keyword'].isin(keyword)].sort_values(by=['Keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>AnimatorsPal</td>\n",
       "      <td>RT AnimationVFXJob Marvel Streaming Production...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>['freelanceremotecontractworkfromhome', 'produ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>SirFowlman</td>\n",
       "      <td>RT OleLoken I drew a lady on a vespa then i dr...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Australia</td>\n",
       "      <td>['2d', '2danimation']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>cadetcollar</td>\n",
       "      <td>this 100 true lol as an animation student i wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>she/her | 22</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>_Fungai_</td>\n",
       "      <td>RT animationjobs 2D Production Supervisor job ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>peridopp</td>\n",
       "      <td>RT KoalaDingoLabo The koala facing the frogsga...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>['gamedev', 'madewithunity', 'unity3d', 'metro...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Keyword          User  \\\n",
       "0  2d animation  AnimatorsPal   \n",
       "1  2d animation    SirFowlman   \n",
       "2  2d animation   cadetcollar   \n",
       "3  2d animation      _Fungai_   \n",
       "4  2d animation      peridopp   \n",
       "\n",
       "                                               Tweet Language        Time  \\\n",
       "0  RT AnimationVFXJob Marvel Streaming Production...       en  2022-03-21   \n",
       "1  RT OleLoken I drew a lady on a vespa then i dr...       en  2022-03-21   \n",
       "2  this 100 true lol as an animation student i wa...       en  2022-03-21   \n",
       "3  RT animationjobs 2D Production Supervisor job ...       en  2022-03-21   \n",
       "4  RT KoalaDingoLabo The koala facing the frogsga...       en  2022-03-21   \n",
       "\n",
       "  User Location                                            Hashtag  Polarity  \\\n",
       "0        Berlin  ['freelanceremotecontractworkfromhome', 'produ...   neutral   \n",
       "1     Australia                              ['2d', '2danimation']  positive   \n",
       "2  she/her | 22                                                 []  positive   \n",
       "3           NaN                                                 []   neutral   \n",
       "4      Scotland  ['gamedev', 'madewithunity', 'unity3d', 'metro...   neutral   \n",
       "\n",
       "   Likes  Retweet  Sentiment  \n",
       "0    0.0      1.0   0.000000  \n",
       "1    0.0     50.0   0.750000  \n",
       "2    5.0      0.0   0.359524  \n",
       "3    0.0      1.0   0.000000  \n",
       "4    0.0     14.0   0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.newUnion()\n",
    "dm.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184552\n",
      "147067\n",
      "47060\n",
      "\n",
      "\n",
      "\n",
      " positive    184552\n",
      "neutral     147067\n",
      "negative     47060\n",
      "Name: Polarity, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "393848"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = dm.df['Polarity'].value_counts()\n",
    "print(p['positive'])\n",
    "print(p['neutral'])\n",
    "print(p['negative'])\n",
    "print('\\n\\n\\n',p)\n",
    "dm.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm.collectwords(dm.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixar', 'bl anime']\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8b5bcc5adb4ebd86a065b5c16f1392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bl anime</td>\n",
       "      <td>Ethensifa</td>\n",
       "      <td>Hello if you like K-pop, kdrama, fan fictions,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>bl anime</td>\n",
       "      <td>_LunaticDestiny</td>\n",
       "      <td>Wow spotify really playing all the songs from ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>bl anime</td>\n",
       "      <td>MystyFeline</td>\n",
       "      <td>RT dowonsgf To celebrate my 1st Anniversary he...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>bl anime</td>\n",
       "      <td>_TineMorris</td>\n",
       "      <td>RT dowonsgf To celebrate my 1st Anniversary he...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>18+</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>bl anime</td>\n",
       "      <td>jinjinjin12492</td>\n",
       "      <td>RT dowonsgf To celebrate my 1st Anniversary he...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Manila City, National Capital</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>pixar</td>\n",
       "      <td>Naa9530</td>\n",
       "      <td>RT modooborahae BTS x Disney dubbed Disney mov...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>pixar</td>\n",
       "      <td>_Nurul_Qifa_</td>\n",
       "      <td>RT shadowtwts BTS made a surprise appearance d...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>Alor Setar, Kedah</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>pixar</td>\n",
       "      <td>Dongkeystar07</td>\n",
       "      <td>RT sunflowercharts BTStwt ปรากฏตัวในวิดีโองานป...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['BTS', 'Jimin', 'RM']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>pixar</td>\n",
       "      <td>spsidey</td>\n",
       "      <td>lariesmanis Adaa based on pixar field arigato ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>pixar</td>\n",
       "      <td>Joylilworld</td>\n",
       "      <td>RT Variety Domee Shi the director of TurningRe...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>Angoulême</td>\n",
       "      <td>['TurningRed']</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39929 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Keyword             User  \\\n",
       "0    bl anime        Ethensifa   \n",
       "849  bl anime  _LunaticDestiny   \n",
       "848  bl anime      MystyFeline   \n",
       "847  bl anime      _TineMorris   \n",
       "846  bl anime   jinjinjin12492   \n",
       "..        ...              ...   \n",
       "572     pixar          Naa9530   \n",
       "571     pixar     _Nurul_Qifa_   \n",
       "570     pixar    Dongkeystar07   \n",
       "584     pixar          spsidey   \n",
       "601     pixar      Joylilworld   \n",
       "\n",
       "                                                 Tweet Language        Time  \\\n",
       "0    Hello if you like K-pop, kdrama, fan fictions,...      NaN  2022-03-19   \n",
       "849  Wow spotify really playing all the songs from ...       en  2022-04-01   \n",
       "848  RT dowonsgf To celebrate my 1st Anniversary he...       en  2022-04-01   \n",
       "847  RT dowonsgf To celebrate my 1st Anniversary he...       en  2022-04-01   \n",
       "846  RT dowonsgf To celebrate my 1st Anniversary he...       en  2022-04-01   \n",
       "..                                                 ...      ...         ...   \n",
       "572  RT modooborahae BTS x Disney dubbed Disney mov...       en  2022-03-28   \n",
       "571  RT shadowtwts BTS made a surprise appearance d...       en  2022-03-28   \n",
       "570  RT sunflowercharts BTStwt ปรากฏตัวในวิดีโองานป...       th  2022-03-28   \n",
       "584  lariesmanis Adaa based on pixar field arigato ...       en  2022-03-28   \n",
       "601  RT Variety Domee Shi the director of TurningRe...       en  2022-04-07   \n",
       "\n",
       "                      User Location                 Hashtag  Polarity  Likes  \\\n",
       "0                               NaN                     NaN       NaN    0.0   \n",
       "849                             NaN                      []  positive    0.0   \n",
       "848                          Cavite                      []   neutral    0.0   \n",
       "847                             18+                      []   neutral    0.0   \n",
       "846  Manila City, National Capital                       []   neutral    0.0   \n",
       "..                              ...                     ...       ...    ...   \n",
       "572                             NaN                      []   neutral    0.0   \n",
       "571               Alor Setar, Kedah                      []  positive    0.0   \n",
       "570                             NaN  ['BTS', 'Jimin', 'RM']  positive    0.0   \n",
       "584                             NaN                      []   neutral    0.0   \n",
       "601                       Angoulême          ['TurningRed']  positive    0.0   \n",
       "\n",
       "     Retweet  Sentiment  \n",
       "0        1.0        NaN  \n",
       "849      0.0   0.195238  \n",
       "848     50.0   0.000000  \n",
       "847     27.0   0.000000  \n",
       "846     27.0   0.000000  \n",
       "..       ...        ...  \n",
       "572   1281.0   0.000000  \n",
       "571    103.0   0.500000  \n",
       "570   2247.0  66.670000  \n",
       "584      0.0   0.000000  \n",
       "601   2001.0   0.500000  \n",
       "\n",
       "[39929 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tws = Twitter_Scrap()\n",
    "tws.setdataframe(dm.df)\n",
    "tws.searchkeys(['pixar','bl anime'],'eiei','2022-4-17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"collectkeys\"\n",
    "path = str(folder+'/'+'pixarr')\n",
    "os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Shounen_w</td>\n",
       "      <td>@seongisdaddy never gonna happen ue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Selly_wins</td>\n",
       "      <td>RT NFTSHOUNEN SHOUNEN x CubeX To celebrate we ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Sukabumi, Indonesia</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1424.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>shounen</td>\n",
       "      <td>MondhaschenA</td>\n",
       "      <td>RT MangaMoguraRE A new manga series by Amano M...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Aus dem Königreich des Mondes</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>shounen</td>\n",
       "      <td>mitchy728_4star</td>\n",
       "      <td>RT barbiehoekuti NaniwaDanshi will perform Six...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>大胆に境界を越えようかPrincess</td>\n",
       "      <td>['NaniwaDanshi', 'SixTONES']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>shounen</td>\n",
       "      <td>SamTheSouless</td>\n",
       "      <td>PinkZoneAmy I dont care Thats boring asf Its l...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>shounen</td>\n",
       "      <td>nanfneg123</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>shounen</td>\n",
       "      <td>DroopyNFT</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Potacio4</td>\n",
       "      <td>AceX50 Youre misunderstanding Im saying that A...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>shounen</td>\n",
       "      <td>SpecAgentOsoNFT</td>\n",
       "      <td>RT WGMIIndustries WGMI Industries x SHOUNEN To...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>shounen</td>\n",
       "      <td>taliwah</td>\n",
       "      <td>RT retrocrushtv 35 years ago on April 6th 1987...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28523 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Keyword             User  \\\n",
       "0     shounen        Shounen_w   \n",
       "1437  shounen       Selly_wins   \n",
       "1436  shounen     MondhaschenA   \n",
       "1435  shounen  mitchy728_4star   \n",
       "1434  shounen    SamTheSouless   \n",
       "...       ...              ...   \n",
       "817   shounen       nanfneg123   \n",
       "816   shounen        DroopyNFT   \n",
       "815   shounen         Potacio4   \n",
       "826   shounen  SpecAgentOsoNFT   \n",
       "620   shounen          taliwah   \n",
       "\n",
       "                                                  Tweet Language        Time  \\\n",
       "0                   @seongisdaddy never gonna happen ue      NaN  2022-03-19   \n",
       "1437  RT NFTSHOUNEN SHOUNEN x CubeX To celebrate we ...       en  2022-04-01   \n",
       "1436  RT MangaMoguraRE A new manga series by Amano M...       en  2022-04-01   \n",
       "1435  RT barbiehoekuti NaniwaDanshi will perform Six...       en  2022-04-01   \n",
       "1434  PinkZoneAmy I dont care Thats boring asf Its l...       en  2022-04-01   \n",
       "...                                                 ...      ...         ...   \n",
       "817   RT WGMIIndustries WGMI Industries x SHOUNEN To...       en  2022-03-26   \n",
       "816   RT WGMIIndustries WGMI Industries x SHOUNEN To...       en  2022-03-26   \n",
       "815   AceX50 Youre misunderstanding Im saying that A...       en  2022-03-26   \n",
       "826   RT WGMIIndustries WGMI Industries x SHOUNEN To...       en  2022-03-26   \n",
       "620   RT retrocrushtv 35 years ago on April 6th 1987...       en  2022-04-07   \n",
       "\n",
       "                       User Location                       Hashtag  Polarity  \\\n",
       "0                                NaN                           NaN       NaN   \n",
       "1437             Sukabumi, Indonesia                            []   neutral   \n",
       "1436  Aus dem Königreich des Mondes                             []  positive   \n",
       "1435             大胆に境界を越えようかPrincess  ['NaniwaDanshi', 'SixTONES']   neutral   \n",
       "1434                             NaN                            []  negative   \n",
       "...                              ...                           ...       ...   \n",
       "817                              NaN                            []   neutral   \n",
       "816                              NaN                            []   neutral   \n",
       "815                              NaN                            []  positive   \n",
       "826                              NaN                            []   neutral   \n",
       "620                              NaN                            []  positive   \n",
       "\n",
       "      Likes  Retweet  Sentiment  \n",
       "0       1.0      0.0        NaN  \n",
       "1437    0.0   1424.0   0.000000  \n",
       "1436    0.0     20.0   0.136364  \n",
       "1435    0.0    584.0   0.000000  \n",
       "1434    0.0      0.0  -1.000000  \n",
       "...     ...      ...        ...  \n",
       "817     0.0    859.0   0.000000  \n",
       "816     0.0    780.0   0.000000  \n",
       "815     0.0      0.0   0.300000  \n",
       "826     0.0    809.0   0.000000  \n",
       "620     0.0     26.0   0.500000  \n",
       "\n",
       "[28523 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

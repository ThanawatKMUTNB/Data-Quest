{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import shutil\n",
    "from pythainlp.corpus import thai_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  \n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        params = {'text':text}\n",
    "        response = requests.get(self._url, headers=self._headers, params=params)\n",
    "        try:\n",
    "            polarity = str(response.json()['sentiment']['polarity'])\n",
    "        except (KeyError):\n",
    "            polarity = 'neutral'\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d') #dmY ทีหลัง\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        self.keys = list(set(self.df['Keyword'].tolist()))\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def setnewDF(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        self.df = self.unionfile(self.filenames)\n",
    "        return self.df\n",
    "    \n",
    "    def collectfile(self):\n",
    "        self.df[\"Time\"] = pd.to_datetime(self.df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "        keys = list(set(df['Keyword'].tolist()))\n",
    "        folder = \"collectkeys\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)    \n",
    "        for key in keys:\n",
    "            path = str(folder+'/'+key)\n",
    "            dff = self.df.loc[self.df['Keyword'].isin([key])]\n",
    "            days = list(set(dff['Time'].tolist()))\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            for d in days:\n",
    "                dfff = dff.loc[dff['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "    \n",
    "    def newUnion(self,filenames):\n",
    "        self.filenames = filenames\n",
    "        path=os.getcwd()\n",
    "        keys = []\n",
    "        start = 0\n",
    "        for f in glob.glob(path+'/collectkeys/*'):\n",
    "            keyname = os.path.split(f)[-1]\n",
    "            keys.append(keyname)\n",
    "        for k in keys:\n",
    "            for file in glob.glob(path+'/collectkeys/'+k+'/*.csv'):\n",
    "                if start == 0:\n",
    "                    df = pd.read_csv(file)\n",
    "                    start +=1\n",
    "                else:\n",
    "                    dff = pd.read_csv(file)\n",
    "                    df = pd.concat([df,dff])\n",
    "        self.keys = keys\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return\n",
    "        return dff.loc[mask]\n",
    "    \n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectwords(self,dataframe):\n",
    "        #print(dataframe)\n",
    "        dataframe = dataframe.reset_index()\n",
    "        th_stopwords = list(thai_stopwords())\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        word = {}\n",
    "        for index,row in dataframe.iterrows():    #only tweet\n",
    "            if row['Language'] == 'eng':\n",
    "                allwords = row['Tweet'].split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            elif row['Language'] == 'th':\n",
    "                allwords = word_tokenize(row['Tweet'], engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in th_stopwords:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                pass\n",
    "        if 'RT' in word:\n",
    "            del word['RT']  #for twitter\n",
    "        if ' ' in word:\n",
    "            del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        worddf = pd.DataFrame(sortword,columns=['Word','Count'])\n",
    "        return worddf   #word dataframe\n",
    "        #return sortword     #tuple in list\n",
    "    \n",
    "    def deletekeyword(self,keyword):\n",
    "        path=os.getcwd()\n",
    "        for k  in keyword:\n",
    "            shutil.rmtree(path+'//collectkeys//'+k+'//')\n",
    "            self.keys.remove(k)\n",
    "            self.df.drop(self.df[self.df['Keyword']==k].index,inplace = True)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>LinearUwu</td>\n",
       "      <td>RT blutack1966 The future will always be brigh...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>animationjobs</td>\n",
       "      <td>2D Background Artist job in Dicesol Animation ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Global 🌍</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>l3oAlways</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Poland 🇵🇱</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>BiraboneyeVicky</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>vedavasai</td>\n",
       "      <td>Totem Creative Mumbai based animation studio w...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>vasai, Mumbai</td>\n",
       "      <td>['vedavasai', 'animation', 'Studio', 'INFO']</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['บ']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393848 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Keyword             User  \\\n",
       "1      2d animation        LinearUwu   \n",
       "2      2d animation    animationjobs   \n",
       "4      2d animation        l3oAlways   \n",
       "5      2d animation  BiraboneyeVicky   \n",
       "6      2d animation        vedavasai   \n",
       "...             ...              ...   \n",
       "10397   อนิเมะแนะนำ      JokerJokeE7   \n",
       "10398   อนิเมะแนะนำ         AnimeICU   \n",
       "10399   อนิเมะแนะนำ        Ruttapak2   \n",
       "10400   อนิเมะแนะนำ      Creamyyy_mm   \n",
       "10401   อนิเมะแนะนำ          SineTST   \n",
       "\n",
       "                                                   Tweet Language        Time  \\\n",
       "1      RT blutack1966 The future will always be brigh...       en  2022-04-01   \n",
       "2      2D Background Artist job in Dicesol Animation ...       en  2022-04-01   \n",
       "4      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "5      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "6      Totem Creative Mumbai based animation studio w...       en  2022-04-01   \n",
       "...                                                  ...      ...         ...   \n",
       "10397  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-30   \n",
       "10398  แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th  2022-04-05   \n",
       "10399  RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...       th  2022-04-03   \n",
       "10400  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-04-03   \n",
       "10401  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-29   \n",
       "\n",
       "       User Location                                            Hashtag  \\\n",
       "1                NaN                                                 []   \n",
       "2           Global 🌍                                                 []   \n",
       "4         Poland 🇵🇱   ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "5                NaN  ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "6      vasai, Mumbai       ['vedavasai', 'animation', 'Studio', 'INFO']   \n",
       "...              ...                                                ...   \n",
       "10397            NaN                                                 []   \n",
       "10398            NaN        ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']   \n",
       "10399            NaN                                              ['บ']   \n",
       "10400            NaN                                                 []   \n",
       "10401            NaN                                                 []   \n",
       "\n",
       "       Polarity  Likes  Retweet  Sentiment  \n",
       "1      positive    0.0     21.0   0.516667  \n",
       "2      positive    1.0      1.0   0.211039  \n",
       "4      positive    0.0     33.0   0.500000  \n",
       "5      positive    0.0     27.0   0.500000  \n",
       "6      positive    2.0      1.0   0.500000  \n",
       "...         ...    ...      ...        ...  \n",
       "10397   neutral    0.0    192.0   0.000000  \n",
       "10398  positive    5.0      1.0  66.670000  \n",
       "10399   neutral    0.0     10.0   0.000000  \n",
       "10400   neutral    0.0    192.0   0.000000  \n",
       "10401   neutral    0.0    192.0   0.000000  \n",
       "\n",
       "[393848 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ดู', 'ทีวี']\n",
      "['ดู', 'ทีวี']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "text = \"ดูทีวี\"\n",
    "list_word = word_tokenize(text)\n",
    "print(list_word)\n",
    "\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "stopwords = list(thai_stopwords())\n",
    "list_word_not_stopwords = [i for i in list_word if i not in stopwords]\n",
    "print(list_word_not_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddf = dm.collectwords(dm.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>อนิเมะ</td>\n",
       "      <td>14814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>แนะนำ</td>\n",
       "      <td>8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ดู</td>\n",
       "      <td>7752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ซี</td>\n",
       "      <td>6312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bilibili</td>\n",
       "      <td>6165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>เค้า</td>\n",
       "      <td>6084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>โค</td>\n",
       "      <td>6075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>สาย</td>\n",
       "      <td>6056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>วาย</td>\n",
       "      <td>6017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ฟรี</td>\n",
       "      <td>5987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>รางวัล</td>\n",
       "      <td>5911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ยังมี</td>\n",
       "      <td>5896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>นุ</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>กิจกรรม</td>\n",
       "      <td>5883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>นิว</td>\n",
       "      <td>5796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>หัว</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ลุ้น</td>\n",
       "      <td>5730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>กรี๊ด</td>\n",
       "      <td>5704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>thisisoleang</td>\n",
       "      <td>5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>สิทธิ</td>\n",
       "      <td>5685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Count\n",
       "0         อนิเมะ  14814\n",
       "1          แนะนำ   8700\n",
       "2             ดู   7752\n",
       "3             ซี   6312\n",
       "4       Bilibili   6165\n",
       "5           เค้า   6084\n",
       "6             โค   6075\n",
       "7            สาย   6056\n",
       "8            วาย   6017\n",
       "9            ฟรี   5987\n",
       "10        รางวัล   5911\n",
       "11         ยังมี   5896\n",
       "12            นุ   5893\n",
       "13       กิจกรรม   5883\n",
       "14           นิว   5796\n",
       "15           หัว   5765\n",
       "16          ลุ้น   5730\n",
       "17         กรี๊ด   5704\n",
       "18  thisisoleang   5701\n",
       "19         สิทธิ   5685"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worddf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.deletekeyword(['anime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.collectfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path=os.getcwd()\n",
    "shutil.rmtree(path+'//collectkeys//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setnewDF(df1)\n",
    "dm.getperiod('2022-03-21','2022-03-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setdefaultDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dm.collectword()[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dm.collectword()[:100],columns=['Word','Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)\n",
    "dm.formatdatetime('Time')\n",
    "print(dm.df['Time'].min().strftime('%Y/%m/%d'))\n",
    "print(dm.df['Time'].max().strftime('%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','ต่างโลก','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','อนิเมะ','2d animation','อนิเมะแนะนำ','japan animation']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\"\n",
    "keyword = list(map(lambda x: x.lower(), keyword))\n",
    "keyword\n",
    "print(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('อนิเมะ', 1007)\n",
      "('ทิ้ง', 504)\n",
      "('นิยาย', 503)\n",
      "('เรื่อง', 456)\n",
      "('ตลาดนัด', 392)\n",
      "('โลก', 377)\n",
      "('ตอน', 296)\n",
      "('แฟนตาซี', 274)\n",
      "('คน', 254)\n",
      "('ดู', 232)\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.corpus import thai_stopwords\n",
    "th_stopwords = list(thai_stopwords())\n",
    "\n",
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['ต่างโลก','อนิเมะ'])]\n",
    "dff = dff.reset_index()##\n",
    "word = {}\n",
    "\n",
    "for index,row in dff.iterrows():##\n",
    "    if row['Language'] == 'en':\n",
    "        allwords = row['Tweet'].split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    elif row['Language'] == 'th':   #\n",
    "        allwords = word_tokenize(row['Tweet'], engine='newmm')  #\n",
    "        for w in allwords: \n",
    "            if w not in th_stopwords:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        pass\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.reset_index()\n",
    "for index,row in dff.iterrows():\n",
    "    print(row['Tweet'],row['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "df = dm.unionfile(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "folder = \"collectkeys\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for key in keys:\n",
    "    path = str(folder+'/'+key)\n",
    "    dff = df.loc[df['Keyword'].isin([key])]\n",
    "    days = list(set(dff['Time'].tolist()))\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for d in days:\n",
    "        dfff = dff.loc[dff['Time'].isin([d])]\n",
    "        dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "\n",
    "    def getSentiment(self,text):\n",
    "\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d')\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "        \n",
    "    def searchkeys(self,keyword):\n",
    "        self.keys = self.df['Keyword'].tolist()\n",
    "        self.keys = list(set(self.keys))\n",
    "        keyword = keyword.lower()\n",
    "        if keyword in self.keys:\n",
    "            return self.df.loc[self.df['Keyword']==keyword]\n",
    "        else:\n",
    "            print(f'{keyword} not in Database. Do you want to search?')\n",
    "            Ans = str(input()).lower()                                                  #wait for GUI\n",
    "            if Ans == 'yes':\n",
    "                self.keys.append(keyword)\n",
    "                # self.savedata()\n",
    "                # return self.df.loc[self.df['Keyword']==keyword]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        return self.df\n",
    "\n",
    "    def getdate(self,since,until):  ####edit\n",
    "        self.df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        mask = (self.df['Time']>=since) & (self.df['Time']<=until)\n",
    "        return self.df.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ['tweet_data_1932022.csv','tweet_data_2032022.csv','tweet_data_2132022_1.csv',\n",
    "            'tweet_data_2232022.csv','tweet_data_2332022.csv','tweet_data_2432022.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Shounen_w</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@seongisdaddy never gonna happen ue</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>shounen</td>\n",
       "      <td>batkniqht</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yeah they probably all read manga cuz they’re ...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>shounen</td>\n",
       "      <td>lerinarin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Most of anime shounen in nutshell\\nhttps://t.c...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>shounen</td>\n",
       "      <td>AJShaw17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@BlueExe99 Where'd you find the clean version ...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>shounen</td>\n",
       "      <td>voidgender_fizz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@jemibuni Me when my favorite character is a c...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15679</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Metavins1</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>en</td>\n",
       "      <td>HapeBeast HQ</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15680</th>\n",
       "      <td>shounen</td>\n",
       "      <td>Renatta01760514</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>en</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>shounen</td>\n",
       "      <td>ohkeyokey</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>shounen</td>\n",
       "      <td>purplef30074728</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT n12smrai WL Giveaway for Shounen Ill be giv...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>shounen</td>\n",
       "      <td>TitouPok01</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT GodJiraslove WL GIVEAWAYWe are giving away ...</td>\n",
       "      <td>2022-03-24</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4842 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Keyword             User  Retweet  Likes  \\\n",
       "2006   shounen        Shounen_w      0.0    1.0   \n",
       "2007   shounen        batkniqht      0.0    0.0   \n",
       "2008   shounen        lerinarin      0.0    0.0   \n",
       "2009   shounen         AJShaw17      0.0    0.0   \n",
       "2010   shounen  voidgender_fizz      0.0    1.0   \n",
       "...        ...              ...      ...    ...   \n",
       "15679  shounen        Metavins1   1016.0    0.0   \n",
       "15680  shounen  Renatta01760514   1016.0    0.0   \n",
       "15681  shounen        ohkeyokey   1716.0    0.0   \n",
       "15682  shounen  purplef30074728    148.0    0.0   \n",
       "15683  shounen       TitouPok01   1102.0    0.0   \n",
       "\n",
       "                                                   Tweet       Time Language  \\\n",
       "2006                 @seongisdaddy never gonna happen ue 2022-03-19      NaN   \n",
       "2007   yeah they probably all read manga cuz they’re ... 2022-03-19      NaN   \n",
       "2008   Most of anime shounen in nutshell\\nhttps://t.c... 2022-03-19      NaN   \n",
       "2009   @BlueExe99 Where'd you find the clean version ... 2022-03-19      NaN   \n",
       "2010   @jemibuni Me when my favorite character is a c... 2022-03-19      NaN   \n",
       "...                                                  ...        ...      ...   \n",
       "15679  RT GodJiraslove WL GIVEAWAYWe are giving away ... 2022-03-24       en   \n",
       "15680  RT GodJiraslove WL GIVEAWAYWe are giving away ... 2022-03-24       en   \n",
       "15681  RT GodJiraslove WL GIVEAWAYWe are giving away ... 2022-03-24       en   \n",
       "15682  RT n12smrai WL Giveaway for Shounen Ill be giv... 2022-03-24       en   \n",
       "15683  RT GodJiraslove WL GIVEAWAYWe are giving away ... 2022-03-24       en   \n",
       "\n",
       "      User Location Hashtag Polarity  Sentiment  \n",
       "2006            NaN     NaN      NaN        NaN  \n",
       "2007            NaN     NaN      NaN        NaN  \n",
       "2008            NaN     NaN      NaN        NaN  \n",
       "2009            NaN     NaN      NaN        NaN  \n",
       "2010            NaN     NaN      NaN        NaN  \n",
       "...             ...     ...      ...        ...  \n",
       "15679  HapeBeast HQ      []  neutral        0.0  \n",
       "15680     Indonesia      []  neutral        0.0  \n",
       "15681           NaN      []  neutral        0.0  \n",
       "15682           NaN      []  neutral        0.0  \n",
       "15683           NaN      []  neutral        0.0  \n",
       "\n",
       "[4842 rows x 11 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)\n",
    "dm.formatdatetime('Time')\n",
    "#dm.sortdf(['Keyword','Time'])\n",
    "#dm.getdate('2022-03-17','2022-03-23')\n",
    "dm.searchkeys('shounen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Time</th>\n",
       "      <th>Language</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>animation</td>\n",
       "      <td>SagarGa39569425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The plot of \"Don't Mess With The Cultivation B...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>animation</td>\n",
       "      <td>Aarya_pimparkar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I love the art style in \"Love After Marriage\" ...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>animation</td>\n",
       "      <td>jkhomezi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>You'll find companies looking for a \"Graphic D...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>animation</td>\n",
       "      <td>blazingwish66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The plot of \"Martial Rebel\" is like a roller c...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>animation</td>\n",
       "      <td>DI0RDENKI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I think diluc should get a new idle animation ...</td>\n",
       "      <td>2022-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>thanxxjk</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT todojamy</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['แนะนำอ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>tinyreview2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT bbrinkk bilibili</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>th</td>\n",
       "      <td>ประเทศไทย</td>\n",
       "      <td>['สาววายถ']</td>\n",
       "      <td>positive</td>\n",
       "      <td>97.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>dalbluenim</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT primpytd Bilibili</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>btf_effectx</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86 EIGHTYSIX Attack on Titan</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>th</td>\n",
       "      <td>she/her, th-en ♡</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>mydissocute</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT btfeffectx 86 EIGHTYSIX</td>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>negative</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6507 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Keyword             User  Retweet  Likes  \\\n",
       "55      animation  SagarGa39569425      0.0    0.0   \n",
       "68      animation  Aarya_pimparkar      0.0    0.0   \n",
       "77      animation         jkhomezi      0.0    0.0   \n",
       "165     animation    blazingwish66      0.0    0.0   \n",
       "167     animation        DI0RDENKI      0.0    0.0   \n",
       "...           ...              ...      ...    ...   \n",
       "2975  อนิเมะแนะนำ         thanxxjk     20.0    0.0   \n",
       "2976  อนิเมะแนะนำ      tinyreview2     37.0    0.0   \n",
       "2978  อนิเมะแนะนำ       dalbluenim     27.0    0.0   \n",
       "2979  อนิเมะแนะนำ      btf_effectx      5.0    1.0   \n",
       "2980  อนิเมะแนะนำ      mydissocute      5.0    0.0   \n",
       "\n",
       "                                                  Tweet       Time Language  \\\n",
       "55    The plot of \"Don't Mess With The Cultivation B... 2022-03-19      NaN   \n",
       "68    I love the art style in \"Love After Marriage\" ... 2022-03-19      NaN   \n",
       "77    You'll find companies looking for a \"Graphic D... 2022-03-19      NaN   \n",
       "165   The plot of \"Martial Rebel\" is like a roller c... 2022-03-19      NaN   \n",
       "167   I think diluc should get a new idle animation ... 2022-03-19      NaN   \n",
       "...                                                 ...        ...      ...   \n",
       "2975                                        RT todojamy 2022-03-21       th   \n",
       "2976                                RT bbrinkk bilibili 2022-03-21       th   \n",
       "2978                               RT primpytd Bilibili 2022-03-21       th   \n",
       "2979                       86 EIGHTYSIX Attack on Titan 2022-03-21       th   \n",
       "2980                         RT btfeffectx 86 EIGHTYSIX 2022-03-21       th   \n",
       "\n",
       "         User Location      Hashtag  Polarity  Sentiment  \n",
       "55                 NaN          NaN       NaN        NaN  \n",
       "68                 NaN          NaN       NaN        NaN  \n",
       "77                 NaN          NaN       NaN        NaN  \n",
       "165                NaN          NaN       NaN        NaN  \n",
       "167                NaN          NaN       NaN        NaN  \n",
       "...                ...          ...       ...        ...  \n",
       "2975               NaN   ['แนะนำอ']  positive      66.67  \n",
       "2976         ประเทศไทย  ['สาววายถ']  positive      97.30  \n",
       "2978               NaN           []  positive      75.00  \n",
       "2979  she/her, th-en ♡           []  positive      83.33  \n",
       "2980               NaN           []  negative      66.67  \n",
       "\n",
       "[6507 rows x 11 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022_1.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20638    EUREKA SEVEN GOOD NIGHT SLEEP TIGHT YOUNG LOVE...\n",
       "15904                                           RT etalork\n",
       "15905                                         RT Algiz7375\n",
       "15906                                         RT Suparak1a\n",
       "15908                       RT NeptheduckNovel OpenThisSky\n",
       "                               ...                        \n",
       "2930                                            RT lermloe\n",
       "2931                                            RT lermloe\n",
       "2932                                       RT tingjapanese\n",
       "2933                                            RT lermloe\n",
       "2934                                       RT tingjapanese\n",
       "Name: Tweet, Length: 3198, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from nltk.corpus import stopwords\n",
    "import langdetect\n",
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    "headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2432022.csv','tweet_data_2332022.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "keys = (df['Keyword']=='ต่างโลก') | (df['Keyword']=='อนิเมะ')\n",
    "dff = df.loc[keys].sort_values(by=['Language','Keyword'])\n",
    "word = {}\n",
    "\n",
    "for i in dff['Tweet']:\n",
    "    if langdetect.detect(i) != 'th':\n",
    "        allwords = i.split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        data = {'text':i}\n",
    "        response = requests.post(url, data=data, headers=headers)\n",
    "        allwords = response.json()['preprocess']['keyword']\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "del word['RT']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There\n",
      "tree\n",
      "near\n",
      "river\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': {'score': '88.89', 'polarity-neg': False, 'polarity-pos': True, 'polarity': 'positive'}, 'preprocess': {'input': 'สาขานี้พนักงานน่ารักให้บริการดี', 'neg': [], 'pos': ['น่ารัก', 'ให้บริการดี'], 'segmented': ['สาขา', 'นี้', 'พนักงาน', 'น่ารัก', 'ให้บริการดี'], 'keyword': ['สาขา', 'พนักงาน']}, 'alert': [], 'comparative': [], 'associative': [{'ent-pos': [], 'polarity-neg': False, 'endIndex': 20, 'polarity-pos': True, 'beginIndex': 7, 'text': 'พนักงานน่ารัก', 'ent-neg': [], 'asp': ['พนักงาน']}], 'intention': {'request': '0', 'sentiment': '88.89', 'question': '0', 'announcement': '0'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['สาขา', 'พนักงาน']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['harem',\n",
       " 'อนิเมะ',\n",
       " 'school life',\n",
       " 'japan animation',\n",
       " 'disney animation',\n",
       " 'from novel',\n",
       " '2d animation',\n",
       " 'ต่างโลก',\n",
       " 'anime',\n",
       " 'anime comedy',\n",
       " 'อนิเมะแนะนำ',\n",
       " 'animation',\n",
       " 'slice of life anime',\n",
       " 'mappa',\n",
       " 'sport anime',\n",
       " '3d',\n",
       " 'seinen',\n",
       " 'shoujo',\n",
       " 'bl anime',\n",
       " '3d animation',\n",
       " 'attack on titan',\n",
       " 'pixar',\n",
       " 'fantasy anime',\n",
       " 'from manga',\n",
       " 'shounen',\n",
       " 'anime romance',\n",
       " 'school life anime',\n",
       " 'shounen ai',\n",
       " 'animation studio']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = list(set(df['Keyword'].tolist()))\n",
    "key"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

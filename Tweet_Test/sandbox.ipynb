{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  \n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        params = {'text':text}\n",
    "        response = requests.get(self._url, headers=self._headers, params=params)\n",
    "        try:\n",
    "            polarity = str(response.json()['sentiment']['polarity'])\n",
    "        except (KeyError):\n",
    "            polarity = 'neutral'\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d') #dmY ทีหลัง\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        self.keys = list(set(self.df['Keyword'].tolist()))\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def setnewDF(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        self.df = self.unionfile(self.filenames)\n",
    "        return self.df\n",
    "    \n",
    "    def collectfile(self):\n",
    "        self.df[\"Time\"] = pd.to_datetime(self.df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "        keys = list(set(df['Keyword'].tolist()))\n",
    "        folder = \"collectkeys\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)    \n",
    "        for key in keys:\n",
    "            path = str(folder+'/'+key)\n",
    "            dff = self.df.loc[self.df['Keyword'].isin([key])]\n",
    "            days = list(set(dff['Time'].tolist()))\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            for d in days:\n",
    "                dfff = dff.loc[dff['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "    \n",
    "    def newUnion(self,filenames):\n",
    "        self.filenames = filenames\n",
    "        path=os.getcwd()\n",
    "        keys = []\n",
    "        start = 0\n",
    "        for f in glob.glob(path+'/collectkeys/*'):\n",
    "            keyname = os.path.split(f)[-1]\n",
    "            keys.append(keyname)\n",
    "        for k in keys:\n",
    "            for file in glob.glob(path+'/collectkeys/'+k+'/*.csv'):\n",
    "                if start == 0:\n",
    "                    df = pd.read_csv(file)\n",
    "                    start +=1\n",
    "                else:\n",
    "                    dff = pd.read_csv(file)\n",
    "                    df = pd.concat([df,dff])\n",
    "        self.keys = keys\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return\n",
    "        return dff.loc[mask]\n",
    "    \n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectwords(self,dataframe):\n",
    "        #nltk.download('stopwords')          #important\n",
    "        dataframe = dataframe.reset_index()\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        word = {}\n",
    "        for index,row in dataframe.iterrows():    #only tweet\n",
    "            if row['Language'] == 'eng':\n",
    "                allwords = row['Tweet'].split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            elif row['Language'] == 'th':\n",
    "                allwords = word_tokenize(row['Tweet'], engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                pass\n",
    "        if 'RT' in word:\n",
    "            del word['RT']  #for twitter\n",
    "        if ' ' in word:\n",
    "            del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        worddf = pd.DataFrame(sortword,columns=['Word','Count'])\n",
    "        return worddf   #word dataframe\n",
    "        #return sortword     #tuple in list\n",
    "    \n",
    "    def deletekeyword(self,keyword):\n",
    "        path=os.getcwd()\n",
    "        for k  in keyword:\n",
    "            shutil.rmtree(path+'//collectkeys//'+k+'//')\n",
    "            self.keys.remove(k)\n",
    "            self.df.drop(self.df[self.df['Keyword']==k].index,inplace = True)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>LinearUwu</td>\n",
       "      <td>RT blutack1966 The future will always be brigh...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>animationjobs</td>\n",
       "      <td>2D Background Artist job in Dicesol Animation ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Global 🌍</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>l3oAlways</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Poland 🇵🇱</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>BiraboneyeVicky</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>vedavasai</td>\n",
       "      <td>Totem Creative Mumbai based animation studio w...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>vasai, Mumbai</td>\n",
       "      <td>['vedavasai', 'animation', 'Studio', 'INFO']</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['บ']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393848 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Keyword             User  \\\n",
       "1      2d animation        LinearUwu   \n",
       "2      2d animation    animationjobs   \n",
       "4      2d animation        l3oAlways   \n",
       "5      2d animation  BiraboneyeVicky   \n",
       "6      2d animation        vedavasai   \n",
       "...             ...              ...   \n",
       "10397   อนิเมะแนะนำ      JokerJokeE7   \n",
       "10398   อนิเมะแนะนำ         AnimeICU   \n",
       "10399   อนิเมะแนะนำ        Ruttapak2   \n",
       "10400   อนิเมะแนะนำ      Creamyyy_mm   \n",
       "10401   อนิเมะแนะนำ          SineTST   \n",
       "\n",
       "                                                   Tweet Language        Time  \\\n",
       "1      RT blutack1966 The future will always be brigh...       en  2022-04-01   \n",
       "2      2D Background Artist job in Dicesol Animation ...       en  2022-04-01   \n",
       "4      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "5      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "6      Totem Creative Mumbai based animation studio w...       en  2022-04-01   \n",
       "...                                                  ...      ...         ...   \n",
       "10397  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-30   \n",
       "10398  แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th  2022-04-05   \n",
       "10399  RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...       th  2022-04-03   \n",
       "10400  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-04-03   \n",
       "10401  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-29   \n",
       "\n",
       "       User Location                                            Hashtag  \\\n",
       "1                NaN                                                 []   \n",
       "2           Global 🌍                                                 []   \n",
       "4         Poland 🇵🇱   ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "5                NaN  ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "6      vasai, Mumbai       ['vedavasai', 'animation', 'Studio', 'INFO']   \n",
       "...              ...                                                ...   \n",
       "10397            NaN                                                 []   \n",
       "10398            NaN        ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']   \n",
       "10399            NaN                                              ['บ']   \n",
       "10400            NaN                                                 []   \n",
       "10401            NaN                                                 []   \n",
       "\n",
       "       Polarity  Likes  Retweet  Sentiment  \n",
       "1      positive    0.0     21.0   0.516667  \n",
       "2      positive    1.0      1.0   0.211039  \n",
       "4      positive    0.0     33.0   0.500000  \n",
       "5      positive    0.0     27.0   0.500000  \n",
       "6      positive    2.0      1.0   0.500000  \n",
       "...         ...    ...      ...        ...  \n",
       "10397   neutral    0.0    192.0   0.000000  \n",
       "10398  positive    5.0      1.0  66.670000  \n",
       "10399   neutral    0.0     10.0   0.000000  \n",
       "10400   neutral    0.0    192.0   0.000000  \n",
       "10401   neutral    0.0    192.0   0.000000  \n",
       "\n",
       "[393848 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/3419822735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewUnion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/2682149435.py\u001b[0m in \u001b[0;36mnewUnion\u001b[1;34m(self, filenames)\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/2682149435.py\u001b[0m in \u001b[0;36mcollectfile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollectfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Time\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Keyword'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"collectkeys\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.newUnion(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>anime</td>\n",
       "      <td>ryuukkkj</td>\n",
       "      <td>RT Based5656 Anime One Piece</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>via láctea</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3267.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>anime</td>\n",
       "      <td>therumblinggg</td>\n",
       "      <td>i watch anime and feel like life is worth living</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>he/him, 21</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>anime</td>\n",
       "      <td>WinterKamado200</td>\n",
       "      <td>danmachianime Where the hell is she</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Brooklyn Park, MN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>anime</td>\n",
       "      <td>lensheerr</td>\n",
       "      <td>RT Husvero After 2 amazing weeks I finally fin...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>somewhere not here</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>anime</td>\n",
       "      <td>jdoublep95</td>\n",
       "      <td>RT KimetsuVibings Anime Demon Slayer</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['บ']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286045 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Keyword             User  \\\n",
       "6161         anime         ryuukkkj   \n",
       "6162         anime    therumblinggg   \n",
       "6163         anime  WinterKamado200   \n",
       "6164         anime        lensheerr   \n",
       "6165         anime       jdoublep95   \n",
       "...            ...              ...   \n",
       "10397  อนิเมะแนะนำ      JokerJokeE7   \n",
       "10398  อนิเมะแนะนำ         AnimeICU   \n",
       "10399  อนิเมะแนะนำ        Ruttapak2   \n",
       "10400  อนิเมะแนะนำ      Creamyyy_mm   \n",
       "10401  อนิเมะแนะนำ          SineTST   \n",
       "\n",
       "                                                   Tweet Language        Time  \\\n",
       "6161                        RT Based5656 Anime One Piece       en  2022-04-01   \n",
       "6162    i watch anime and feel like life is worth living       en  2022-04-01   \n",
       "6163                 danmachianime Where the hell is she       en  2022-04-01   \n",
       "6164   RT Husvero After 2 amazing weeks I finally fin...       en  2022-04-01   \n",
       "6165                RT KimetsuVibings Anime Demon Slayer       en  2022-04-01   \n",
       "...                                                  ...      ...         ...   \n",
       "10397  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-30   \n",
       "10398  แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th  2022-04-05   \n",
       "10399  RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...       th  2022-04-03   \n",
       "10400  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-04-03   \n",
       "10401  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th  2022-03-29   \n",
       "\n",
       "            User Location                                      Hashtag  \\\n",
       "6161          via láctea                                            []   \n",
       "6162           he/him, 21                                           []   \n",
       "6163    Brooklyn Park, MN                                           []   \n",
       "6164   somewhere not here                                           []   \n",
       "6165                  NaN                                           []   \n",
       "...                   ...                                          ...   \n",
       "10397                 NaN                                           []   \n",
       "10398                 NaN  ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']   \n",
       "10399                 NaN                                        ['บ']   \n",
       "10400                 NaN                                           []   \n",
       "10401                 NaN                                           []   \n",
       "\n",
       "       Polarity  Likes  Retweet  Sentiment  \n",
       "6161    neutral    0.0   3267.0       0.00  \n",
       "6162   positive    0.0      0.0       0.30  \n",
       "6163    neutral    1.0      0.0       0.00  \n",
       "6164   positive    0.0      1.0       0.30  \n",
       "6165    neutral    0.0   3274.0       0.00  \n",
       "...         ...    ...      ...        ...  \n",
       "10397   neutral    0.0    192.0       0.00  \n",
       "10398  positive    5.0      1.0      66.67  \n",
       "10399   neutral    0.0     10.0       0.00  \n",
       "10400   neutral    0.0    192.0       0.00  \n",
       "10401   neutral    0.0    192.0       0.00  \n",
       "\n",
       "[286045 rows x 11 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.deletekeyword(['anime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.collectfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path=os.getcwd()\n",
    "shutil.rmtree(path+'//collectkeys//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setnewDF(df1)\n",
    "dm.getperiod('2022-03-21','2022-03-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setdefaultDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dm.collectword()[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dm.collectword()[:100],columns=['Word','Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)\n",
    "dm.formatdatetime('Time')\n",
    "print(dm.df['Time'].min().strftime('%Y/%m/%d'))\n",
    "print(dm.df['Time'].max().strftime('%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','ต่างโลก','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','อนิเมะ','2d animation','อนิเมะแนะนำ','japan animation']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\"\n",
    "keyword = list(map(lambda x: x.lower(), keyword))\n",
    "keyword\n",
    "print(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['pixar','อนิเมะ'])]\n",
    "dff = dff.reset_index()##\n",
    "word = {}\n",
    "\n",
    "for index,row in dff.iterrows():##\n",
    "    if row['Language'] == 'en':\n",
    "        allwords = row['Tweet'].split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    elif row['Language'] == 'th':   #\n",
    "        allwords = word_tokenize(row['Tweet'], engine='newmm')  #\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        pass\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.reset_index()\n",
    "for index,row in dff.iterrows():\n",
    "    print(row['Tweet'],row['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': {'score': '88.89', 'polarity-neg': False, 'polarity-pos': True, 'polarity': 'positive'}, 'preprocess': {'input': 'สาขานี้พนักงานน่ารักให้บริการดี', 'neg': [], 'pos': ['น่ารัก', 'ให้บริการดี'], 'segmented': ['สาขา', 'นี้', 'พนักงาน', 'น่ารัก', 'ให้บริการดี'], 'keyword': ['สาขา', 'พนักงาน']}, 'alert': [], 'comparative': [], 'associative': [{'ent-pos': [], 'polarity-neg': False, 'endIndex': 20, 'polarity-pos': True, 'beginIndex': 7, 'text': 'พนักงานน่ารัก', 'ent-neg': [], 'asp': ['พนักงาน']}], 'intention': {'request': '0', 'sentiment': '88.89', 'question': '0', 'announcement': '0'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['สาขา', 'พนักงาน']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'สาขานี้พนักงานน่ารักให้บริการดี'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>LinearUwu</td>\n",
       "      <td>RT blutack1966 The future will always be brigh...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 07:18:10+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>animationjobs</td>\n",
       "      <td>2D Background Artist job in Dicesol Animation ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 07:00:39+00:00</td>\n",
       "      <td>Global 🌍</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>l3oAlways</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 06:43:57+00:00</td>\n",
       "      <td>Poland 🇵🇱</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>BiraboneyeVicky</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 06:06:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>vedavasai</td>\n",
       "      <td>Totem Creative Mumbai based animation studio w...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 11:05:02+00:00</td>\n",
       "      <td>vasai, Mumbai</td>\n",
       "      <td>['vedavasai', 'animation', 'Studio', 'INFO']</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30 04:52:44+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05 11:53:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03 13:21:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['บ']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03 04:02:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>อนิเมะแนะนำ</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29 13:18:32+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393848 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Keyword             User  \\\n",
       "1      2d animation        LinearUwu   \n",
       "2      2d animation    animationjobs   \n",
       "4      2d animation        l3oAlways   \n",
       "5      2d animation  BiraboneyeVicky   \n",
       "6      2d animation        vedavasai   \n",
       "...             ...              ...   \n",
       "10397   อนิเมะแนะนำ      JokerJokeE7   \n",
       "10398   อนิเมะแนะนำ         AnimeICU   \n",
       "10399   อนิเมะแนะนำ        Ruttapak2   \n",
       "10400   อนิเมะแนะนำ      Creamyyy_mm   \n",
       "10401   อนิเมะแนะนำ          SineTST   \n",
       "\n",
       "                                                   Tweet Language  \\\n",
       "1      RT blutack1966 The future will always be brigh...       en   \n",
       "2      2D Background Artist job in Dicesol Animation ...       en   \n",
       "4      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en   \n",
       "5      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en   \n",
       "6      Totem Creative Mumbai based animation studio w...       en   \n",
       "...                                                  ...      ...   \n",
       "10397  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th   \n",
       "10398  แนะนำ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th   \n",
       "10399  RT museacgth ก่อนที่อนิเมะ บันทึกการเดินทางต่า...       th   \n",
       "10400  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th   \n",
       "10401  RT thisisoleang สายวายต้องกรี๊ด เค้ามีกิจกรรมใ...       th   \n",
       "\n",
       "                            Time  User Location  \\\n",
       "1      2022-04-01 07:18:10+00:00            NaN   \n",
       "2      2022-04-01 07:00:39+00:00       Global 🌍   \n",
       "4      2022-04-01 06:43:57+00:00     Poland 🇵🇱    \n",
       "5      2022-04-01 06:06:23+00:00            NaN   \n",
       "6      2022-04-01 11:05:02+00:00  vasai, Mumbai   \n",
       "...                          ...            ...   \n",
       "10397  2022-03-30 04:52:44+00:00            NaN   \n",
       "10398  2022-04-05 11:53:58+00:00            NaN   \n",
       "10399  2022-04-03 13:21:19+00:00            NaN   \n",
       "10400  2022-04-03 04:02:13+00:00            NaN   \n",
       "10401  2022-03-29 13:18:32+00:00            NaN   \n",
       "\n",
       "                                                 Hashtag  Polarity  Likes  \\\n",
       "1                                                     []  positive    0.0   \n",
       "2                                                     []  positive    1.0   \n",
       "4      ['LGG', 'websitedesign', 'GraphicDesign', 'vid...  positive    0.0   \n",
       "5      ['LGG', 'websitedesign', 'GraphicDesign', 'vid...  positive    0.0   \n",
       "6           ['vedavasai', 'animation', 'Studio', 'INFO']  positive    2.0   \n",
       "...                                                  ...       ...    ...   \n",
       "10397                                                 []   neutral    0.0   \n",
       "10398        ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']  positive    5.0   \n",
       "10399                                              ['บ']   neutral    0.0   \n",
       "10400                                                 []   neutral    0.0   \n",
       "10401                                                 []   neutral    0.0   \n",
       "\n",
       "       Retweet  Sentiment  \n",
       "1         21.0   0.516667  \n",
       "2          1.0   0.211039  \n",
       "4         33.0   0.500000  \n",
       "5         27.0   0.500000  \n",
       "6          1.0   0.500000  \n",
       "...        ...        ...  \n",
       "10397    192.0   0.000000  \n",
       "10398      1.0  66.670000  \n",
       "10399     10.0   0.000000  \n",
       "10400    192.0   0.000000  \n",
       "10401    192.0   0.000000  \n",
       "\n",
       "[393848 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "df = dm.unionfile(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "folder = \"collectkeys\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for key in keys:\n",
    "    path = str(folder+'/'+key)\n",
    "    dff = df.loc[df['Keyword'].isin([key])]\n",
    "    days = list(set(dff['Time'].tolist()))\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for d in days:\n",
    "        dfff = dff.loc[dff['Time'].isin([d])]\n",
    "        dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

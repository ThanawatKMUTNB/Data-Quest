{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "from pythainlp import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import langdetect\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')  \n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        ##-------------------- twitter --------------------##\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "        consumer_key = \"EaFU9nJw2utR0lo2PUmJE3VZy\"\n",
    "        consumer_secret = \"DsZuVw0tEl6GHhyK08tunsOE9ICSfwplEhRDMQwB8VIqngZ6i8\"\n",
    "        access_token = \"759317188863897600-nuwQmcYfDX8lvdRyw2eCD6fMRMkLzzZ\"\n",
    "        access_token_secret = 'zFFc5OJywNMBrRAblI7kFV62ZTZPHfTU1Q5kZ1cKzUupD'\n",
    "        auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        self._api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        self._url = \"https://api.aiforthai.in.th/ssense\"                     \n",
    "        self._headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}\n",
    "\n",
    "        self.keys = []\n",
    "        self.df = None\n",
    "        self._start = 0\n",
    "        self.filenames = []\n",
    "\n",
    "    def getSentimentENG(self,text):\n",
    "        if TextBlob(text).sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif TextBlob(text).sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def getSentimentTH(self,text):\n",
    "        text = re.sub(r'[%]',' ',text)\n",
    "        params = {'text':text}\n",
    "        response = requests.get(self._url, headers=self._headers, params=params)\n",
    "        try:\n",
    "            polarity = str(response.json()['sentiment']['polarity'])\n",
    "        except (KeyError):\n",
    "            polarity = 'neutral'\n",
    "        return polarity\n",
    "\n",
    "    def formatdatetime(self,column):\n",
    "        self.df[column] = pd.to_datetime(self.df[column]).dt.strftime('%Y/%m/%d') #dmY ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á\n",
    "        self.df[column] = pd.to_datetime(self.df[column])\n",
    "    \n",
    "    def sortdf(self,columns):\n",
    "        self.df.sort_values(by=columns,inplace=True)\n",
    "        return self.df\n",
    "\n",
    "    def unionfile(self,filenames):              #type filename -> list\n",
    "        self._start = 0\n",
    "        self.filenames = filenames\n",
    "        for file in filenames:\n",
    "            df1 = pd.read_csv(file)\n",
    "            if self._start != 0:\n",
    "                self.df = pd.concat([self.df,df1])\n",
    "                self.df.drop_duplicates(keep='last',inplace=True)\n",
    "            else:\n",
    "                self.df = df1\n",
    "                self._start += 1\n",
    "        self.keys = list(set(self.df['Keyword'].tolist()))\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def setnewDF(self,dataframe):\n",
    "        self.df = dataframe\n",
    "        return self.df\n",
    "    \n",
    "    def setdefaultDF(self):\n",
    "        self.df = self.unionfile(self.filenames)\n",
    "        return self.df\n",
    "    \n",
    "    def collectfile(self):\n",
    "        self.df[\"Time\"] = pd.to_datetime(self.df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "        keys = list(set(df['Keyword'].tolist()))\n",
    "        folder = \"collectkeys\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)    \n",
    "        for key in keys:\n",
    "            path = str(folder+'/'+key)\n",
    "            dff = self.df.loc[self.df['Keyword'].isin([key])]\n",
    "            days = list(set(dff['Time'].tolist()))\n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            for d in days:\n",
    "                dfff = dff.loc[dff['Time'].isin([d])]\n",
    "                dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)\n",
    "    \n",
    "    def newUnion(self,filenames):\n",
    "        self.filenames = filenames\n",
    "        path=os.getcwd()\n",
    "        keys = []\n",
    "        start = 0\n",
    "        for f in glob.glob(path+'/collectkeys/*'):\n",
    "            keyname = os.path.split(f)[-1]\n",
    "            keys.append(keyname)\n",
    "        for k in keys:\n",
    "            for file in glob.glob(path+'/collectkeys/'+k+'/*.csv'):\n",
    "                if start == 0:\n",
    "                    df = pd.read_csv(file)\n",
    "                    start +=1\n",
    "                else:\n",
    "                    dff = pd.read_csv(file)\n",
    "                    df = pd.concat([df,dff])\n",
    "        self.keys = keys\n",
    "        self.collectfile()\n",
    "        return self.df\n",
    "    \n",
    "    def getperiod(self,since,until):  ####column for twitter\n",
    "        self.formatdatetime('Time')\n",
    "        dff = self.df\n",
    "        dff.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "        if since == None and until != None:\n",
    "            mask = (dff['Time']<=until)\n",
    "        elif since != None and until == None:\n",
    "            mask = (dff['Time']>=since)\n",
    "        elif since != None and until != None:\n",
    "            mask = (dff['Time']>=since) & (dff['Time']<=until)\n",
    "        else:\n",
    "            return\n",
    "        return dff.loc[mask]\n",
    "    \n",
    "    def getrowwithkeys(self,keys):              #type keys -> list\n",
    "        df = self.df\n",
    "        return df.loc[df['Keyword'].isin(keys)]\n",
    "\n",
    "    def collectwords(self,dataframe):\n",
    "        #nltk.download('stopwords')          #important\n",
    "        dataframe = dataframe.reset_index()\n",
    "        en_stops = set(stopwords.words('english'))\n",
    "        word = {}\n",
    "        for index,row in dataframe.iterrows():    #only tweet\n",
    "            if row['Language'] == 'eng':\n",
    "                allwords = row['Tweet'].split()\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            elif row['Language'] == 'th':\n",
    "                allwords = word_tokenize(row['Tweet'], engine='newmm')\n",
    "                for w in allwords: \n",
    "                    if w not in en_stops:\n",
    "                        if w in word:\n",
    "                            word[w] += 1\n",
    "                        else:\n",
    "                            word[w] = 1\n",
    "            else:\n",
    "                pass\n",
    "        if 'RT' in word:\n",
    "            del word['RT']  #for twitter\n",
    "        if ' ' in word:\n",
    "            del word[' ']   #for thai language\n",
    "        sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "        worddf = pd.DataFrame(sortword,columns=['Word','Count'])\n",
    "        return worddf   #word dataframe\n",
    "        #return sortword     #tuple in list\n",
    "    \n",
    "    def deletekeyword(self,keyword):\n",
    "        path=os.getcwd()\n",
    "        for k  in keyword:\n",
    "            shutil.rmtree(path+'//collectkeys//'+k+'//')\n",
    "            self.keys.remove(k)\n",
    "            self.df.drop(self.df[self.df['Keyword']==k].index,inplace = True)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>LinearUwu</td>\n",
       "      <td>RT blutack1966 The future will always be brigh...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>animationjobs</td>\n",
       "      <td>2D Background Artist job in Dicesol Animation ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Global üåç</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>l3oAlways</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Poland üáµüá±</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>BiraboneyeVicky</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>vedavasai</td>\n",
       "      <td>Totem Creative Mumbai based animation studio w...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>vasai, Mumbai</td>\n",
       "      <td>['vedavasai', 'animation', 'Studio', 'INFO']</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['‡∏ö']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393848 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Keyword             User  \\\n",
       "1      2d animation        LinearUwu   \n",
       "2      2d animation    animationjobs   \n",
       "4      2d animation        l3oAlways   \n",
       "5      2d animation  BiraboneyeVicky   \n",
       "6      2d animation        vedavasai   \n",
       "...             ...              ...   \n",
       "10397   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      JokerJokeE7   \n",
       "10398   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥         AnimeICU   \n",
       "10399   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥        Ruttapak2   \n",
       "10400   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      Creamyyy_mm   \n",
       "10401   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥          SineTST   \n",
       "\n",
       "                                                   Tweet Language        Time  \\\n",
       "1      RT blutack1966 The future will always be brigh...       en  2022-04-01   \n",
       "2      2D Background Artist job in Dicesol Animation ...       en  2022-04-01   \n",
       "4      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "5      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en  2022-04-01   \n",
       "6      Totem Creative Mumbai based animation studio w...       en  2022-04-01   \n",
       "...                                                  ...      ...         ...   \n",
       "10397  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-03-30   \n",
       "10398  ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th  2022-04-05   \n",
       "10399  RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...       th  2022-04-03   \n",
       "10400  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-04-03   \n",
       "10401  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-03-29   \n",
       "\n",
       "       User Location                                            Hashtag  \\\n",
       "1                NaN                                                 []   \n",
       "2           Global üåç                                                 []   \n",
       "4         Poland üáµüá±   ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "5                NaN  ['LGG', 'websitedesign', 'GraphicDesign', 'vid...   \n",
       "6      vasai, Mumbai       ['vedavasai', 'animation', 'Studio', 'INFO']   \n",
       "...              ...                                                ...   \n",
       "10397            NaN                                                 []   \n",
       "10398            NaN        ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']   \n",
       "10399            NaN                                              ['‡∏ö']   \n",
       "10400            NaN                                                 []   \n",
       "10401            NaN                                                 []   \n",
       "\n",
       "       Polarity  Likes  Retweet  Sentiment  \n",
       "1      positive    0.0     21.0   0.516667  \n",
       "2      positive    1.0      1.0   0.211039  \n",
       "4      positive    0.0     33.0   0.500000  \n",
       "5      positive    0.0     27.0   0.500000  \n",
       "6      positive    2.0      1.0   0.500000  \n",
       "...         ...    ...      ...        ...  \n",
       "10397   neutral    0.0    192.0   0.000000  \n",
       "10398  positive    5.0      1.0  66.670000  \n",
       "10399   neutral    0.0     10.0   0.000000  \n",
       "10400   neutral    0.0    192.0   0.000000  \n",
       "10401   neutral    0.0    192.0   0.000000  \n",
       "\n",
       "[393848 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/3419822735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewUnion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/2682149435.py\u001b[0m in \u001b[0;36mnewUnion\u001b[1;34m(self, filenames)\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdff\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4996/2682149435.py\u001b[0m in \u001b[0;36mcollectfile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollectfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Time\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Keyword'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"collectkeys\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.newUnion(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6161</th>\n",
       "      <td>anime</td>\n",
       "      <td>ryuukkkj</td>\n",
       "      <td>RT Based5656 Anime One Piece</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>via l√°ctea</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3267.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>anime</td>\n",
       "      <td>therumblinggg</td>\n",
       "      <td>i watch anime and feel like life is worth living</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>he/him, 21</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>anime</td>\n",
       "      <td>WinterKamado200</td>\n",
       "      <td>danmachianime Where the hell is she</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Brooklyn Park, MN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>anime</td>\n",
       "      <td>lensheerr</td>\n",
       "      <td>RT Husvero After 2 amazing weeks I finally fin...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>somewhere not here</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>anime</td>\n",
       "      <td>jdoublep95</td>\n",
       "      <td>RT KimetsuVibings Anime Demon Slayer</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['‡∏ö']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286045 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Keyword             User  \\\n",
       "6161         anime         ryuukkkj   \n",
       "6162         anime    therumblinggg   \n",
       "6163         anime  WinterKamado200   \n",
       "6164         anime        lensheerr   \n",
       "6165         anime       jdoublep95   \n",
       "...            ...              ...   \n",
       "10397  ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      JokerJokeE7   \n",
       "10398  ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥         AnimeICU   \n",
       "10399  ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥        Ruttapak2   \n",
       "10400  ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      Creamyyy_mm   \n",
       "10401  ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥          SineTST   \n",
       "\n",
       "                                                   Tweet Language        Time  \\\n",
       "6161                        RT Based5656 Anime One Piece       en  2022-04-01   \n",
       "6162    i watch anime and feel like life is worth living       en  2022-04-01   \n",
       "6163                 danmachianime Where the hell is she       en  2022-04-01   \n",
       "6164   RT Husvero After 2 amazing weeks I finally fin...       en  2022-04-01   \n",
       "6165                RT KimetsuVibings Anime Demon Slayer       en  2022-04-01   \n",
       "...                                                  ...      ...         ...   \n",
       "10397  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-03-30   \n",
       "10398  ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th  2022-04-05   \n",
       "10399  RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...       th  2022-04-03   \n",
       "10400  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-04-03   \n",
       "10401  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th  2022-03-29   \n",
       "\n",
       "            User Location                                      Hashtag  \\\n",
       "6161          via l√°ctea                                            []   \n",
       "6162           he/him, 21                                           []   \n",
       "6163    Brooklyn Park, MN                                           []   \n",
       "6164   somewhere not here                                           []   \n",
       "6165                  NaN                                           []   \n",
       "...                   ...                                          ...   \n",
       "10397                 NaN                                           []   \n",
       "10398                 NaN  ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']   \n",
       "10399                 NaN                                        ['‡∏ö']   \n",
       "10400                 NaN                                           []   \n",
       "10401                 NaN                                           []   \n",
       "\n",
       "       Polarity  Likes  Retweet  Sentiment  \n",
       "6161    neutral    0.0   3267.0       0.00  \n",
       "6162   positive    0.0      0.0       0.30  \n",
       "6163    neutral    1.0      0.0       0.00  \n",
       "6164   positive    0.0      1.0       0.30  \n",
       "6165    neutral    0.0   3274.0       0.00  \n",
       "...         ...    ...      ...        ...  \n",
       "10397   neutral    0.0    192.0       0.00  \n",
       "10398  positive    5.0      1.0      66.67  \n",
       "10399   neutral    0.0     10.0       0.00  \n",
       "10400   neutral    0.0    192.0       0.00  \n",
       "10401   neutral    0.0    192.0       0.00  \n",
       "\n",
       "[286045 rows x 11 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.deletekeyword(['anime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.collectfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "path=os.getcwd()\n",
    "shutil.rmtree(path+'//collectkeys//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dm.getrowwithkeys(['shounen']).sort_values('Keyword')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setnewDF(df1)\n",
    "dm.getperiod('2022-03-21','2022-03-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setdefaultDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dm.collectword()[:10]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dm.collectword()[:100],columns=['Word','Count'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.unionfile(filename)\n",
    "dm.formatdatetime('Time')\n",
    "print(dm.df['Time'].min().strftime('%Y/%m/%d'))\n",
    "print(dm.df['Time'].max().strftime('%Y/%m/%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','‡∏ï‡πà‡∏≤‡∏á‡πÇ‡∏•‡∏Å','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞','2d animation','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥','japan animation']\n",
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "filename = ['tweet_data_2032022.csv','tweet_data_1932022.csv','tweet_data_2132022.csv','tweet_data_2232022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%Y/%m/%d')\n",
    "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime('%d %m %Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df.sort_values(by=['Time','Keyword'],inplace=True)\n",
    "\n",
    "#time = list(set(df['Time'].tolist()))\n",
    "mask = (df['Time']>='2022-03-19') & (df['Time']<='2022-03-21')\n",
    "#mask = (df['Time']>='19-03-2022') & (df['Time']<='21-03-2022')\n",
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"\"\n",
    "keyword = list(map(lambda x: x.lower(), keyword))\n",
    "keyword\n",
    "print(type(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "filename = ['tweet_data_2732022.csv']\n",
    "i = 0\n",
    "for file in filename:\n",
    "    df1 = pd.read_csv(file)\n",
    "    if i != 0:\n",
    "        df = pd.concat([df,df1])\n",
    "        df.drop_duplicates(keep='last',inplace=True)\n",
    "    else:\n",
    "        df = df1\n",
    "        i += 1\n",
    "        \n",
    "dff = df.loc[df['Keyword'].isin(['pixar','‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞'])]\n",
    "dff = dff.reset_index()##\n",
    "word = {}\n",
    "\n",
    "for index,row in dff.iterrows():##\n",
    "    if row['Language'] == 'en':\n",
    "        allwords = row['Tweet'].split()\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    elif row['Language'] == 'th':   #\n",
    "        allwords = word_tokenize(row['Tweet'], engine='newmm')  #\n",
    "        for w in allwords: \n",
    "            if w not in en_stops:\n",
    "                if w in word:\n",
    "                    word[w] += 1\n",
    "                else:\n",
    "                    word[w] = 1\n",
    "    else:\n",
    "        pass\n",
    "del word['RT']\n",
    "del word[' ']\n",
    "sortword = sorted(word.items(),key=lambda x:x[1],reverse=True)\n",
    "for i in sortword[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.reset_index()\n",
    "for index,row in dff.iterrows():\n",
    "    print(row['Tweet'],row['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "all_words = ['There', 'is', 'a', 'tree','near','the','river']\n",
    "for word in all_words: \n",
    "    if word not in en_stops:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': {'score': '88.89', 'polarity-neg': False, 'polarity-pos': True, 'polarity': 'positive'}, 'preprocess': {'input': '‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ', 'neg': [], 'pos': ['‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å', '‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ'], 'segmented': ['‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ô‡∏µ‡πâ', '‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô', '‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å', '‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ'], 'keyword': ['‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô']}, 'alert': [], 'comparative': [], 'associative': [{'ent-pos': [], 'polarity-neg': False, 'endIndex': 20, 'polarity-pos': True, 'beginIndex': 7, 'text': '‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å', 'ent-neg': [], 'asp': ['‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô']}], 'intention': {'request': '0', 'sentiment': '88.89', 'question': '0', 'announcement': '0'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = '‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡∏µ'\n",
    " \n",
    "data = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"vIQAf35aRkc7QUbR1fTPvzvtkqtSKAaz\"\n",
    "    }\n",
    " \n",
    "response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "print(response.json())\n",
    "response.json()['preprocess']['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(set(df['Keyword'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Language</th>\n",
       "      <th>Time</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>LinearUwu</td>\n",
       "      <td>RT blutack1966 The future will always be brigh...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 07:18:10+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>animationjobs</td>\n",
       "      <td>2D Background Artist job in Dicesol Animation ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 07:00:39+00:00</td>\n",
       "      <td>Global üåç</td>\n",
       "      <td>[]</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.211039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>l3oAlways</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 06:43:57+00:00</td>\n",
       "      <td>Poland üáµüá±</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>BiraboneyeVicky</td>\n",
       "      <td>RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 06:06:23+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LGG', 'websitedesign', 'GraphicDesign', 'vid...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2d animation</td>\n",
       "      <td>vedavasai</td>\n",
       "      <td>Totem Creative Mumbai based animation studio w...</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-04-01 11:05:02+00:00</td>\n",
       "      <td>vasai, Mumbai</td>\n",
       "      <td>['vedavasai', 'animation', 'Studio', 'INFO']</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>JokerJokeE7</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-30 04:52:44+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>AnimeICU</td>\n",
       "      <td>‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-05 11:53:58+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Ruttapak2</td>\n",
       "      <td>RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03 13:21:19+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['‡∏ö']</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>Creamyyy_mm</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-04-03 04:02:13+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10401</th>\n",
       "      <td>‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥</td>\n",
       "      <td>SineTST</td>\n",
       "      <td>RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...</td>\n",
       "      <td>th</td>\n",
       "      <td>2022-03-29 13:18:32+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393848 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Keyword             User  \\\n",
       "1      2d animation        LinearUwu   \n",
       "2      2d animation    animationjobs   \n",
       "4      2d animation        l3oAlways   \n",
       "5      2d animation  BiraboneyeVicky   \n",
       "6      2d animation        vedavasai   \n",
       "...             ...              ...   \n",
       "10397   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      JokerJokeE7   \n",
       "10398   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥         AnimeICU   \n",
       "10399   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥        Ruttapak2   \n",
       "10400   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥      Creamyyy_mm   \n",
       "10401   ‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥          SineTST   \n",
       "\n",
       "                                                   Tweet Language  \\\n",
       "1      RT blutack1966 The future will always be brigh...       en   \n",
       "2      2D Background Artist job in Dicesol Animation ...       en   \n",
       "4      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en   \n",
       "5      RT irshema LGGGUYS ALWAYS TELL U SURE DEAL LET...       en   \n",
       "6      Totem Creative Mumbai based animation studio w...       en   \n",
       "...                                                  ...      ...   \n",
       "10397  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th   \n",
       "10398  ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ AKEBIchan SonoBisqueDollWaKoiWoSuru Part...       th   \n",
       "10399  RT museacgth ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏¥‡πÄ‡∏°‡∏∞ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≤...       th   \n",
       "10400  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th   \n",
       "10401  RT thisisoleang ‡∏™‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏µ‡πä‡∏î ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÉ...       th   \n",
       "\n",
       "                            Time  User Location  \\\n",
       "1      2022-04-01 07:18:10+00:00            NaN   \n",
       "2      2022-04-01 07:00:39+00:00       Global üåç   \n",
       "4      2022-04-01 06:43:57+00:00     Poland üáµüá±    \n",
       "5      2022-04-01 06:06:23+00:00            NaN   \n",
       "6      2022-04-01 11:05:02+00:00  vasai, Mumbai   \n",
       "...                          ...            ...   \n",
       "10397  2022-03-30 04:52:44+00:00            NaN   \n",
       "10398  2022-04-05 11:53:58+00:00            NaN   \n",
       "10399  2022-04-03 13:21:19+00:00            NaN   \n",
       "10400  2022-04-03 04:02:13+00:00            NaN   \n",
       "10401  2022-03-29 13:18:32+00:00            NaN   \n",
       "\n",
       "                                                 Hashtag  Polarity  Likes  \\\n",
       "1                                                     []  positive    0.0   \n",
       "2                                                     []  positive    1.0   \n",
       "4      ['LGG', 'websitedesign', 'GraphicDesign', 'vid...  positive    0.0   \n",
       "5      ['LGG', 'websitedesign', 'GraphicDesign', 'vid...  positive    0.0   \n",
       "6           ['vedavasai', 'animation', 'Studio', 'INFO']  positive    2.0   \n",
       "...                                                  ...       ...    ...   \n",
       "10397                                                 []   neutral    0.0   \n",
       "10398        ['AKEBI_chan', 'SonoBisqueDollWaKoiWoSuru']  positive    5.0   \n",
       "10399                                              ['‡∏ö']   neutral    0.0   \n",
       "10400                                                 []   neutral    0.0   \n",
       "10401                                                 []   neutral    0.0   \n",
       "\n",
       "       Retweet  Sentiment  \n",
       "1         21.0   0.516667  \n",
       "2          1.0   0.211039  \n",
       "4         33.0   0.500000  \n",
       "5         27.0   0.500000  \n",
       "6          1.0   0.500000  \n",
       "...        ...        ...  \n",
       "10397    192.0   0.000000  \n",
       "10398      1.0  66.670000  \n",
       "10399     10.0   0.000000  \n",
       "10400    192.0   0.000000  \n",
       "10401    192.0   0.000000  \n",
       "\n",
       "[393848 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "df = dm.unionfile(filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Time\"] = pd.to_datetime(df[\"Time\"]).dt.strftime('%Y-%m-%d')\n",
    "keys = list(set(df['Keyword'].tolist()))\n",
    "folder = \"collectkeys\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for key in keys:\n",
    "    path = str(folder+'/'+key)\n",
    "    dff = df.loc[df['Keyword'].isin([key])]\n",
    "    days = list(set(dff['Time'].tolist()))\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    for d in days:\n",
    "        dfff = dff.loc[dff['Time'].isin([d])]\n",
    "        dfff.to_csv(path+'/'+key+'_'+d+'.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "%run ./fair_keys.ipynb\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "#filename = str(\"tweet_data_\"+str(today.day)+str(today.month)+str(today.year)+\".csv\")\n",
    "filename = 'tweet_data_1932022.csv'\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savedata(keys):\n",
    "    def get_related_tweets(key_word):\n",
    "        tweet_keyword = []\n",
    "        twitter_users = []\n",
    "        #twitter_users_id = []\n",
    "        tweet_time = []\n",
    "        tweet_string = [] \n",
    "        tweet_countRT = []\n",
    "        tweet_fav = []\n",
    "        for tweet in tw.Cursor(api.search_tweets,q=key_word,tweet_mode=\"extended\",include_entities=True).items(40):\n",
    "                if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "                    if tweet.lang == \"en\":\n",
    "                        twitter_users.append(tweet.user.screen_name)\n",
    "                        #twitter_users_id.append(tweet.user.id)\n",
    "                        tweet_time.append(tweet.created_at)\n",
    "                        tweet_string.append(tweet.full_text)\n",
    "                        tweet_countRT.append(tweet.retweet_count)\n",
    "                        tweet_fav.append(tweet.favorite_count)\n",
    "                        tweet_keyword.append(key_word)\n",
    "        df = pd.DataFrame({'Keyword':tweet_keyword,'User':twitter_users,'Retweet':tweet_countRT,'Likes':tweet_fav, 'Tweet': tweet_string, 'Time': tweet_time})\n",
    "        #df.to_csv(f\"{key_word}.csv\")\n",
    "        return df\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    filename = 'tweet_data_1932022.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    os.remove(filename)\n",
    "\n",
    "    for keyword in keys:\n",
    "        df = pd.concat([df,get_related_tweets(keyword)])\n",
    "\n",
    "    df.drop_duplicates(keep='last',inplace=True)\n",
    "    df.sort_values(by=['Keyword'],inplace=True)\n",
    "    df.to_csv(filename,encoding='utf-8',index=False)\n",
    "    print('save complete',current_time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sport anime', 'bl anime', 'seinen', 'harem', 'mappa', 'from manga', 'anime comedy', 'animation studio', 'anime romance', 'school life', 'anime', 'shounen', 'shoujo', 'from novel', 'shounen ai', 'animation', 'pixar', 'fantasy anime', 'slice of life anime']\n",
      "Keyword: pixar\n",
      "                                                  Tweet\n",
      "0     @nas_no1r Soul, Spider-Man, princes and frog, ...\n",
      "1          Love it so much  ü•π‚ù§Ô∏è https://t.co/F7TnCxSk6I\n",
      "2     @Superherofparis @dovecharts @Pixar @notladybu...\n",
      "3     Coco is one of Pixar‚Äôs best films. https://t.c...\n",
      "4     @rynluvszeha pixar jimin vs. walmart jimin‚Ä¶ pi...\n",
      "...                                                 ...\n",
      "1454  @newsfrmhome are you trying to say anime is re...\n",
      "1455  if i could watch a pixar movie for the first t...\n",
      "1456  how to market a movie in 2022 üòë\\n\\nhttps://t.c...\n",
      "1457  @cosmicfizzypop To be fair it wouldn't be the ...\n",
      "1458  Still weird to me that Pixar is making a sci-f...\n",
      "\n",
      "[95 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "keys = df['Keyword'].tolist()\n",
    "keys = list(set(keys))\n",
    "print(keys)\n",
    "keyword = str(input('Enter Keyword: ')).lower()\n",
    "print('Keyword:',keyword)\n",
    "if keyword not in keys:\n",
    "    print(f'{keyword} not in Database. Do you want to search?')\n",
    "    Ans = str(input()).lower()\n",
    "    print(Ans)\n",
    "    if Ans == 'yes':\n",
    "        keys.append(keyword)\n",
    "        df = savedata(keys)\n",
    "        print(df.loc[df['Keyword']==keyword,['Tweet']])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "else:\n",
    "    print(df.loc[df['Keyword']==keyword,['Tweet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animation studio', 'anime romance', 'school life', 'shoujo', 'shounen ai', 'animation', 'fantasy anime', 'anime', 'sport anime', 'bl anime', 'from manga', 'anime comedy', 'pixar', 'from novel', 'shounen', 'seinen', 'harem', 'slice of life anime', 'mappa']\n"
     ]
    }
   ],
   "source": [
    "print(keys)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "\n",
    "%run ./fair_keys.ipynb\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    "headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['bl anime','anime comedy','anime romance','ต่างโลก','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','อนิเมะ','2d animation','อนิเมะแนะนำ','japan animation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "def remove_url_th(txt):\n",
    "    return \" \".join(re.sub(\"([^\\u0E00-\\u0E7Fa-zA-Z' ]|^'|'$|''|(\\w+:\\/\\/\\S+))\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(text):\n",
    "    regex = \"#(\\w+)\" \n",
    "    hashtag_list = re.findall(regex, text)\n",
    "    return hashtag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    # set sentiment\n",
    "    if TextBlob(text).sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif TextBlob(text).sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savedata():\n",
    "    def get_related_tweets(key_word):\n",
    "        tweet_keyword = []\n",
    "        twitter_users = []\n",
    "        twitter_users_location = []\n",
    "        tweet_hashtag = []\n",
    "        tweet_time = []\n",
    "        tweet_string = [] \n",
    "        tweet_countRT = []\n",
    "        tweet_fav = []\n",
    "        tweet_sentiment = []\n",
    "        tweet_polarity = []\n",
    "        tweet_language = []\n",
    "        for tweet in tw.Cursor(api.search_tweets,\n",
    "                                q=key_word,\n",
    "                                tweet_mode=\"extended\",\n",
    "                                include_entities=True).items(100):\n",
    "                                \n",
    "            if(tweet.lang == 'en' or tweet.lang == 'th'):\n",
    "                twitter_users.append(tweet.user.screen_name)#\n",
    "                twitter_users_location.append(tweet.user.location)#\n",
    "                tweet_time.append(tweet.created_at)#\n",
    "                tweet_countRT.append(tweet.retweet_count)#\n",
    "                tweet_fav.append(tweet.favorite_count)#\n",
    "                tweet_keyword.append(key_word)#\n",
    "                tweet_hashtag.append(str(extract_hashtags(tweet.full_text)))#\n",
    "                tweet_language.append(tweet.lang)#\n",
    "                if tweet.lang == 'en':\n",
    "                    tweet_string.append(remove_url(tweet.full_text))#\n",
    "                    tweet_polarity.append(getSentiment(tweet.full_text))\n",
    "                    tweet_sentiment.append(TextBlob(tweet.full_text).sentiment.polarity)\n",
    "                elif tweet.lang == 'th':\n",
    "                    text = re.sub(r'[%]',' ',tweet.full_text)\n",
    "                    params = {'text':text}\n",
    "                    response = requests.get(url, headers=headers, params=params)\n",
    "                    tweet_string.append(remove_url_th(tweet.full_text))\n",
    "                    try:\n",
    "                        polarity = str(response.json()['sentiment']['polarity'])\n",
    "                        sentiment = str(response.json()['sentiment']['score'])\n",
    "                    except (KeyError):\n",
    "                        polarity = 'neutral'\n",
    "                        sentiment = 0\n",
    "                    tweet_polarity.append(polarity)\n",
    "                    tweet_sentiment.append(sentiment)\n",
    "\n",
    "        df = pd.DataFrame({'Keyword':tweet_keyword,'User':twitter_users,'Tweet': tweet_string,'Language':tweet_language, 'Time': tweet_time,'User Location':twitter_users_location,\n",
    "                            'Hashtag':tweet_hashtag,'Polarity':tweet_polarity,'Likes':tweet_fav,'Retweet':tweet_countRT,'Sentiment':tweet_sentiment})\n",
    "        return df\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print('\\nstart saving @',current_time)\n",
    "    today = datetime.today()\n",
    "    filename = str(\"tweet_data_\"+str(today.day)+str(today.month)+str(today.year)+\".csv\")\n",
    "\n",
    "    if filename not in glob.glob(\"*.csv\"):\n",
    "        df = pd.DataFrame(columns=['Keyword','User','Tweet','Language','Time','User Location','Hashtag','Polarity','Likes','Retweet','Sentiment'])\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "    \n",
    "    for keyword in keys:\n",
    "        df = pd.concat([df,get_related_tweets(keyword)])\n",
    "\n",
    "    df.drop_duplicates(keep='last',inplace=True)\n",
    "    df.sort_values(by=['Keyword'],inplace=True)\n",
    "    if filename in glob.glob(\"*.csv\"):\n",
    "        os.remove(filename)\n",
    "    df.to_csv(filename,encoding='utf-8',index=False)\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print('save complete @',current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start saving @ 19:26:48\n",
      "save complete @ 19:28:15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26084/31574550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "savedata()\n",
    "schedule.every(15).minutes.do(savedata)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    " \n",
    "# url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "# text = 'RT @manopsi: Russia-Ukraine war ทำให้ supply ข้าวสาลีโลกหายไป 25% ประเทศที่ได้รับผลกระทบมากล้วนเป็นประเทศยากจนในแอฟริกา'\n",
    " \n",
    "# data = {'text':text}\n",
    " \n",
    "# headers = {\n",
    "#     'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"\n",
    "#     }\n",
    " \n",
    "# response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'RT @manopsi: Russia-Ukraine war ทำให้ supply ข้าวสาลีโลกหายไป 25% ประเทศที่ได้รับผลกระทบมากล้วนเป็นประเทศยากจนในแอฟริกา'\n",
    "# re.sub(r'[%]',' ',text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

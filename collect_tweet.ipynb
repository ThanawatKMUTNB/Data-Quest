{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "from textblob import TextBlob \n",
    "from datetime import datetime\n",
    "\n",
    "%run ./fair_keys.ipynb\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    "headers = {'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys = ['Spy x Family','Genshin Impact']\n",
    "keys = ['bl anime','anime comedy','anime romance','ต่างโลก','anime','animation','shounen','pixar',\n",
    "        'harem','fantasy anime','sport anime','attack on titan','disney animation','animation studio',\n",
    "        'shounen ai','shoujo','อนิเมะ','2d animation','อนิเมะแนะนำ','japan animation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(txt):\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(text):\n",
    "    regex = \"#(\\w+)\" \n",
    "    hashtag_list = re.findall(regex, text)\n",
    "    return hashtag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    # set sentiment\n",
    "    if TextBlob(text).sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif TextBlob(text).sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savedata():\n",
    "    def get_related_tweets(key_word):\n",
    "        tweet_keyword = []\n",
    "        twitter_users = []\n",
    "        twitter_users_location = []\n",
    "        tweet_hashtag = []\n",
    "        tweet_time = []\n",
    "        tweet_string = [] \n",
    "        tweet_countRT = []\n",
    "        tweet_fav = []\n",
    "        tweet_sentiment = []\n",
    "        tweet_polarity = []\n",
    "        tweet_language = []\n",
    "        for tweet in tw.Cursor(api.search_tweets,\n",
    "                                q=key_word,\n",
    "                                tweet_mode=\"extended\",\n",
    "                                include_entities=True).items(100):\n",
    "                                \n",
    "            if(tweet.lang == 'en' or tweet.lang == 'th'):\n",
    "                twitter_users.append(tweet.user.screen_name)#\n",
    "                twitter_users_location.append(tweet.user.location)#\n",
    "                tweet_time.append(tweet.created_at)#\n",
    "                tweet_string.append(remove_url(tweet.full_text))#\n",
    "                tweet_countRT.append(tweet.retweet_count)#\n",
    "                tweet_fav.append(tweet.favorite_count)#\n",
    "                tweet_keyword.append(key_word)#\n",
    "                tweet_hashtag.append(str(extract_hashtags(tweet.full_text)))#\n",
    "                tweet_language.append(tweet.lang)#\n",
    "                if tweet.lang == 'en':\n",
    "                    tweet_polarity.append(getSentiment(tweet.full_text))\n",
    "                    tweet_sentiment.append(TextBlob(tweet.full_text).sentiment.polarity)\n",
    "                elif tweet.lang == 'th':\n",
    "                    text = re.sub(r'[%]',' ',tweet.full_text)\n",
    "                    params = {'text':text}\n",
    "                    response = requests.get(url, headers=headers, params=params)\n",
    "                    #print(url,headers,params)\n",
    "                    #print(response.json())\n",
    "                    #print(str(response.json()['sentiment']['polarity']))\n",
    "                    #print(str(response.json()['sentiment']['score']))\n",
    "                    try:\n",
    "                        polarity = str(response.json()['sentiment']['polarity'])\n",
    "                        sentiment = str(response.json()['sentiment']['score'])\n",
    "                    except (KeyError):\n",
    "                        polarity = 'neutral'\n",
    "                        sentiment = 0\n",
    "                    tweet_polarity.append(polarity)\n",
    "                    tweet_sentiment.append(sentiment)\n",
    "\n",
    "        df = pd.DataFrame({'Keyword':tweet_keyword,'User':twitter_users,'Tweet': tweet_string,'Language':tweet_language, 'Time': tweet_time,'User Location':twitter_users_location,\n",
    "                            'Hashtag':tweet_hashtag,'Polarity':tweet_polarity,'Likes':tweet_fav,'Retweet':tweet_countRT,'Sentiment':tweet_sentiment})\n",
    "        #df.to_csv(f\"{key_word}.csv\")\n",
    "        return df\n",
    "\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    today = datetime.today()\n",
    "    filename = str(\"tweet_data_\"+str(today.day)+str(today.month)+str(today.year)+\".csv\")\n",
    "\n",
    "    if filename not in glob.glob(\"*.csv\"):\n",
    "        df = pd.DataFrame(columns=['Keyword','User','Tweet','Language','Time','User Location','Hashtag','Polarity','Likes','Retweet','Sentiment'])\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "    \n",
    "    for keyword in keys:\n",
    "        df = pd.concat([df,get_related_tweets(keyword)])\n",
    "    #print(df)\n",
    "    #df['Time'] = pd.to_datetime(df['Time'])\n",
    "    #df['Likes'] = df['Likes'].astype(str).astype(int)\n",
    "    #df['Retweet'] = df['Retweet'].astype(str).astype(int)\n",
    "    df.drop_duplicates(keep='last',inplace=True)\n",
    "    df.sort_values(by=['Keyword'],inplace=True)\n",
    "    if filename in glob.glob(\"*.csv\"):\n",
    "        os.remove(filename)\n",
    "    df.to_csv(filename,encoding='utf-8',index=False)\n",
    "    print('save complete',current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save complete 19:35:05\n",
      "save complete 19:51:32\n",
      "save complete 20:07:56\n",
      "save complete 20:24:22\n",
      "save complete 20:40:49\n",
      "save complete 20:57:19\n"
     ]
    }
   ],
   "source": [
    "savedata()\n",
    "schedule.every(15).minutes.do(savedata)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    " \n",
    "# url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "# text = 'RT @manopsi: Russia-Ukraine war ทำให้ supply ข้าวสาลีโลกหายไป 25% ประเทศที่ได้รับผลกระทบมากล้วนเป็นประเทศยากจนในแอฟริกา'\n",
    " \n",
    "# data = {'text':text}\n",
    " \n",
    "# headers = {\n",
    "#     'Apikey': \"0kFkiFLdf4TAyY3JeUT9WVnB5naP6SjW\"\n",
    "#     }\n",
    " \n",
    "# response = requests.post(url, data=data, headers=headers)\n",
    " \n",
    "# response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'RT @manopsi: Russia-Ukraine war ทำให้ supply ข้าวสาลีโลกหายไป 25% ประเทศที่ได้รับผลกระทบมากล้วนเป็นประเทศยากจนในแอฟริกา'\n",
    "# re.sub(r'[%]',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
